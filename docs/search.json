[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Biology",
    "section": "",
    "text": "This is the homepage for Data Science for Biology hosted by the DRP-HCB Bioinformatics Core at the University of Edinburgh.\nThese courses are run annually by the Bioinformatics Core but are also available upon request.\n\n\n\n\n\n\n\n\nFor more information contact Shaun Webb."
  },
  {
    "objectID": "02-Programming.html",
    "href": "02-Programming.html",
    "title": "Programming in R",
    "section": "",
    "text": "Understand the power of R as a programming language\nLearn to use control flow statements in R\nLearn how to write your own functions\nWrite and run reproducible R scripts"
  },
  {
    "objectID": "02-Programming.html#programming-in-r",
    "href": "02-Programming.html#programming-in-r",
    "title": "Programming in R",
    "section": "Programming in R",
    "text": "Programming in R\nR is a powerful programming language that allows you to perform complex data analysis tasks.\nOne of the key advantages of using a programming language like R is that it allows you to automate repetitive tasks and publish code that is fully reproducible.\n\nCode can be shared with others, allowing them to reproduce your results\nCode can be reused for different datasets or analyses\nCode can be run in batch mode, allowing you to process large datasets or run multiple analyses at once"
  },
  {
    "objectID": "02-Programming.html#nested-functions",
    "href": "02-Programming.html#nested-functions",
    "title": "Programming in R",
    "section": "Nested functions",
    "text": "Nested functions\nR functions can be nested inside other functions. This allows you to perform multiple operations on data without creating intermediate variables. For example, you can use the mean function inside the log function to calculate the log of the mean of a set of numbers:\n\nlog( mean(c(3,2,4,6,7)) )\n\n[1] 1.481605\n\n\nR will perform the innermost function first, which is the mean function, and then pass the result to the log function.\nWe can also use nested functions to perform more complex operations. For example, we can use the subset function to filter the cars dataset for rows where the speed is greater than 10, and then use the head function to display the first 3 rows of the filtered dataset:\n\nhead( subset(cars, speed &gt; 10), n = 3)\n\n   speed dist\n10    11   17\n11    11   28\n12    12   14\n\n\nNested functions are very powerful but can make your code difficult to understand if you nest many functions together. Later on we will learn how to use the R pipe operator |&gt; to combine functions in a more natural way."
  },
  {
    "objectID": "02-Programming.html#control-flow-statements",
    "href": "02-Programming.html#control-flow-statements",
    "title": "Programming in R",
    "section": "Control flow statements",
    "text": "Control flow statements\nLet’s begin by looking at some of the basic programming concepts in R. Control flow statements allow you to control the flow of your code based on certain conditions. These are essential for writing complex and dynamic code and common to most programming languages.\n\nIf statements\nIf statements allow you to execute a block of code only if a certain condition is true. For example:\n\nx &lt;- 5\nif (x &gt; 3) {\n  print(\"x is greater than 3\")\n}\n\n[1] \"x is greater than 3\"\n\n\nIf statements can also include an else clause, which allows you to execute a block of code if the condition is false:\n\nx &lt;- 2\nif (x &gt; 3) {\n  print(\"x is greater than 3\")\n} else {\n  print(\"x is not greater than 3\")\n}\n\n[1] \"x is not greater than 3\"\n\n\nIf statements can also be nested, allowing you to check multiple conditions:\n\nx &lt;- 5\nif (x &gt; 3) {\n  print(\"x is greater than 3\")\n  if (x &lt; 10) { ## This if statement only runs if the first condition is true\n    print(\"x is also less than 10\")\n  }\n} else {\n  print(\"x is not greater than 3\")\n}\n\n[1] \"x is greater than 3\"\n[1] \"x is also less than 10\"\n\n\nIf statements can also be combined with logical operators to check multiple conditions at once:\n\nx &lt;- 5\nif (x &gt; 3 && x &lt; 10) {\n  print(\"x is greater than 3 and less than 10\")\n}\n\n[1] \"x is greater than 3 and less than 10\"\n\n\n\nOther logical operators in R\n\n&& - and\n|| - or\n! - not\n== - equal to\n!= - not equal to\n&gt; - greater than\n&lt; - less than\n&gt;= - greater than or equal to\n&lt;= - less than or equal to\n\n\nx &lt;- 5\ny &lt;- 10\nif (x &gt;= 5 && y != 15) {\n  print(\"x is greater than or equal to 5 and y is not equal to 15\")\n}\n\n[1] \"x is greater than or equal to 5 and y is not equal to 15\"\n\n\nIf statements and logic operators can be used with character strings.\n\nx &lt;- \"banana\"\nif (x == \"apple\") {\n  print(\"x is an apple\")\n} else {\n  print(paste(x, \"is not an apple\"))\n}\n\n[1] \"banana is not an apple\"\n\n\nYou can use else if to check multiple conditions in sequence.\n\nx &lt;- \"pear\"\nif (x == \"apple\") {\n  print(\"x is an apple\")\n} else if (x == \"banana\") {\n  print(\"x is a banana\")\n} else {\n  print(paste(x, \"is not an apple or a banana\"))\n}\n\n[1] \"pear is not an apple or a banana\"\n\n\nThe next example has a logical value called draw_plot that is set to FALSE by default. The if statement checks if there are at least 5 data points in the cars dataset after filtering for rows with a speed less than limit. If there are, it sets draw_plot to TRUE and plots the data.\n\n## Only plot data if there are at least 5 data points\nlimit = 20\ndraw_plot = FALSE # Set plot to FALSE by default\ncars_filtered &lt;- subset(cars,cars$speed &lt; limit)\n\nif (nrow(cars_filtered) &gt;= 5) {\n  draw_plot &lt;- TRUE\n}\n\nif (draw_plot == TRUE) {\n  plot(cars)\n}\n\n\n\n\n\n\n\n\nTry setting limit to 7 and rerun the code. What happens?\nIf statements can also be used on vectors or data frames. For example, you can use an if statement to check if a certain value is present in a vector:\n\nx &lt;- c(1, 2, 3, 4, 5)\nif (3 %in% x) {\n  print(\"3 is in the vector x\")\n}\n\n[1] \"3 is in the vector x\"\n\n\nThe %in% is a special operator in R that is used to check if a value is present in a vector or data frame. It returns a logical value indicating if there is a match or not.\n\n\n Challenge:\n\nWrite an if statement to determine if a treatment has a significant effect on gene expression based on a t-test result.\nUse the following code to perform the t-test:\n\n# Sample data frame of gene expression values\nqpcr_example &lt;- data.frame(\n  Condition = c(rep(\"Control\", 5), rep(\"Treatment\", 5)),\n  delta_ct = c(2, 3, 1, 4, 2, 1, 2, 0, 3, 3)\n)\n\n# Perform t-test\nqpcr_result &lt;- t.test(delta_ct ~ Condition, data = qpcr_example, var.equal=TRUE)\n\nPlot a boxplot of the delta_ct values for the control and treatment groups. Add a title to the plot indicating whether the treatment has a significant effect on gene expression based on the t-test result.\nSee if you can add the p-value as a subtitle.\nHINTS\n\nA title can be added with the main argument in the boxplot function.\nYou can use an if statement to determine the title based on the p-value from the t-test result.\nStore the title text in an object and use that object in the main argument of the boxplot function.\nThe p-value can be accessed from the t-test result object with qpcr_result$p.value.\nThe subtitle can be added with the sub argument in the boxplot function.\n\n\n\n\n\nSolution. \n\n Solution:\n\n\n# Check the p-value from the t-test result\nif (qpcr_result$p.value &lt;= 0.05) {\n  title &lt;- \"The treatment has a significant effect on gene expression.\"\n} else {\n  title &lt;- \"The treatment does not have a significant effect on gene expression.\"\n}\n# Plot the boxplot\nboxplot(delta_ct ~ Condition, data = qpcr_example, main = title, sub = paste(\"p-value:\", round(qpcr_result$p.value, 4)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor loops\nFor loops allow you to repeat a block of code a certain number of times. For example, you can use a for loop to iterate over a vector of values:\n\n## Every time the loop runs, the variable i takes on the next value in the sequence from 1 to 5\nfor (i in 1:5) {\n  print(i+1)\n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n\n\nFor loops can also be used to iterate over the rows of a data frame:\n\n# Create a data frame of human patients and their ages\n\ndf &lt;- data.frame(\n  patient = c(\"Eve\", \"Arnold\", \"Fred\"),\n  age = c(10, 30, 35)\n)\ndf\n\n  patient age\n1     Eve  10\n2  Arnold  30\n3    Fred  35\n\n\nWe can use a for loop to iterate over the rows of the data frame and print out a message for each patient:\n\n# Use a for loop to iterate over the rows of the data frame\nfor (i in 1:nrow(df)) {\n  \n  # Use an if statement to classify patients as \"Child\" or \"Adult\" based on their age\n  if (df$age[i] &lt; 18) {\n     classification &lt;- \"Child\"\n  } else{\n     classification &lt;- \"Adult\"\n  }\n  \n  ## Print a statement for each patient\n  print(paste(df$patient[i], \"is visiting the doctor and is classified as\", classification))\n\n}\n\n[1] \"Eve is visiting the doctor and is classified as Child\"\n[1] \"Arnold is visiting the doctor and is classified as Adult\"\n[1] \"Fred is visiting the doctor and is classified as Adult\"\n\n\n\n\n Challenge:\n\nWrite code with control flow that takes a data frame of gene expression values and creates a new column expression classified as “low”, “medium”, or “high” based on the following criteria:\n\nlow if the expression value is less than 10\nmedium if the expression value is between 10 and 100\nhigh if the expression value is greater than 100\n\n\n# Create a sample data frame of gene expression values\ngene_expression &lt;- data.frame(\n  gene = c(\"gene1\", \"gene2\", \"gene3\", \"gene4\", \"gene5\"),\n  expression_value = c(5, 15, 50, 150, 200)\n)\n\n# Create a new column to store the classifications, set to NA by default\ngene_expression$expression &lt;- NA\n\nHINTS\n\nYou can use a for loop to iterate over the rows of the data frame\nUse if else if and else statements to classify the expression values based on the criteria provided.\n\n\n\n\n\nSolution. \n\n Solution:\n\n\n## loop through the rows\nfor (i in 1:nrow(gene_expression)) {\n  \n  ## Check the expression level and assign with if statements\n  if (gene_expression$expression_value[i] &lt; 10) {\n    gene_expression$expression[i] &lt;- \"low\"\n  } else if (gene_expression$expression_value[i] &gt;= 10 && gene_expression$expression_value[i] &lt;= 100) {\n    gene_expression$expression[i] &lt;- \"medium\"\n  } else {\n    gene_expression$expression[i] &lt;- \"high\"\n  }\n\n}\n\n# View the resulting data frame\nprint(gene_expression)\n\n   gene expression_value expression\n1 gene1                5        low\n2 gene2               15     medium\n3 gene3               50     medium\n4 gene4              150       high\n5 gene5              200       high\n\n\n\n\n\n\nFor loops and if statements are used in almost every programming language. They allow you to write code that can adapt to different situations and perform complex tasks.\nHowever, they can be slow to run on large datasets and there are more efficient ways to manipulate data frames in R. We will cover some of these in later modules."
  },
  {
    "objectID": "02-Programming.html#writing-functions",
    "href": "02-Programming.html#writing-functions",
    "title": "Programming in R",
    "section": "Writing functions",
    "text": "Writing functions\nFunctions are reusable blocks of code that perform a specific task. They allow you to break down complex problems into smaller, more manageable pieces.\nYou have already used many functions in R, such as plot(), read.table(), and t.test(). All of these functions have underlying code that performs a specific task when you call the function. In fact, you can print the code for any function in R by simply typing the name of the function without parentheses.\nTry this with the read.table function:\n\nread.table\n\nfunction (file, header = FALSE, sep = \"\", quote = \"\\\"'\", dec = \".\", \n    numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"), row.names, \n    col.names, as.is = !stringsAsFactors, tryLogical = TRUE, \n    na.strings = \"NA\", colClasses = NA, nrows = -1, skip = 0, \n    check.names = TRUE, fill = !blank.lines.skip, strip.white = FALSE, \n    blank.lines.skip = TRUE, comment.char = \"#\", allowEscapes = FALSE, \n    flush = FALSE, stringsAsFactors = FALSE, fileEncoding = \"\", \n    encoding = \"unknown\", text, skipNul = FALSE) \n{\n    if (missing(file) && !missing(text)) {\n        file &lt;- textConnection(text, encoding = \"UTF-8\")\n        encoding &lt;- \"UTF-8\"\n        on.exit(close(file))\n    }\n    if (is.character(file)) {\n        file &lt;- if (nzchar(fileEncoding)) \n            file(file, \"rt\", encoding = fileEncoding)\n        else file(file, \"rt\")\n        on.exit(close(file))\n    }\n    if (!inherits(file, \"connection\")) \n        stop(\"'file' must be a character string or connection\")\n    if (!isOpen(file, \"rt\")) {\n        open(file, \"rt\")\n        on.exit(close(file))\n    }\n    pbEncoding &lt;- if (encoding %in% c(\"\", \"bytes\", \"UTF-8\")) \n        encoding\n    else \"bytes\"\n    numerals &lt;- match.arg(numerals)\n    if (skip &gt; 0L) \n        readLines(file, skip)\n    nlines &lt;- n0lines &lt;- if (nrows &lt; 0L) \n        5\n    else min(5L, (header + nrows))\n    lines &lt;- .External(C_readtablehead, file, nlines, comment.char, \n        blank.lines.skip, quote, sep, skipNul)\n    if (encoding %in% c(\"UTF-8\", \"latin1\")) \n        Encoding(lines) &lt;- encoding\n    nlines &lt;- length(lines)\n    if (!nlines) {\n        if (missing(col.names)) \n            stop(\"no lines available in input\")\n        rlabp &lt;- FALSE\n        cols &lt;- length(col.names)\n    }\n    else {\n        if (all(!nzchar(lines))) \n            stop(\"empty beginning of file\")\n        if (nlines &lt; n0lines && file == 0L) {\n            pushBack(c(lines, lines, \"\"), file, encoding = pbEncoding)\n            on.exit((clearPushBack(stdin())))\n        }\n        else pushBack(c(lines, lines), file, encoding = pbEncoding)\n        first &lt;- scan(file, what = \"\", sep = sep, quote = quote, \n            nlines = 1, quiet = TRUE, skip = 0, strip.white = TRUE, \n            blank.lines.skip = blank.lines.skip, na.strings = character(0), \n            comment.char = comment.char, allowEscapes = allowEscapes, \n            encoding = encoding, skipNul = skipNul)\n        col1 &lt;- if (missing(col.names)) \n            length(first)\n        else length(col.names)\n        col &lt;- numeric(nlines - 1L)\n        if (nlines &gt; 1L) \n            for (i in seq_along(col)) col[i] &lt;- length(scan(file, \n                what = \"\", sep = sep, quote = quote, nlines = 1, \n                quiet = TRUE, skip = 0, strip.white = strip.white, \n                blank.lines.skip = blank.lines.skip, comment.char = comment.char, \n                allowEscapes = allowEscapes, encoding = encoding, \n                skipNul = skipNul))\n        cols &lt;- max(col1, col)\n        rlabp &lt;- (cols - col1) == 1L\n        if (rlabp && missing(header)) \n            header &lt;- TRUE\n        if (!header) \n            rlabp &lt;- FALSE\n        if (header) {\n            .External(C_readtablehead, file, 1L, comment.char, \n                blank.lines.skip, quote, sep, skipNul)\n            if (missing(col.names)) \n                col.names &lt;- first\n            else if (length(first) != length(col.names)) \n                warning(\"header and 'col.names' are of different lengths\")\n        }\n        else if (missing(col.names)) \n            col.names &lt;- paste0(\"V\", 1L:cols)\n        if (length(col.names) + rlabp &lt; cols) \n            stop(\"more columns than column names\")\n        if (fill && length(col.names) &gt; cols) \n            cols &lt;- length(col.names)\n        if (!fill && cols &gt; 0L && length(col.names) &gt; cols) \n            stop(\"more column names than columns\")\n        if (cols == 0L) \n            stop(\"first five rows are empty: giving up\")\n    }\n    if (check.names) \n        col.names &lt;- make.names(col.names, unique = TRUE)\n    if (rlabp) \n        col.names &lt;- c(\"row.names\", col.names)\n    nmColClasses &lt;- names(colClasses)\n    if (is.null(nmColClasses)) {\n        if (length(colClasses) &lt; cols) \n            colClasses &lt;- rep_len(colClasses, cols)\n    }\n    else {\n        tmp &lt;- rep_len(NA_character_, cols)\n        names(tmp) &lt;- col.names\n        i &lt;- match(nmColClasses, col.names, 0L)\n        if (any(i &lt;= 0L)) \n            warning(\"not all columns named in 'colClasses' exist\")\n        tmp[i[i &gt; 0L]] &lt;- colClasses[i &gt; 0L]\n        colClasses &lt;- tmp\n    }\n    what &lt;- rep.int(list(\"\"), cols)\n    names(what) &lt;- col.names\n    colClasses[colClasses %in% c(\"real\", \"double\")] &lt;- \"numeric\"\n    known &lt;- colClasses %in% c(\"logical\", \"integer\", \"numeric\", \n        \"complex\", \"character\", \"raw\")\n    what[known] &lt;- lapply(colClasses[known], do.call, list(0))\n    what[colClasses %in% \"NULL\"] &lt;- list(NULL)\n    keep &lt;- !vapply(what, is.null, NA)\n    data &lt;- scan(file = file, what = what, sep = sep, quote = quote, \n        dec = dec, nmax = nrows, skip = 0, na.strings = na.strings, \n        quiet = TRUE, fill = fill, strip.white = strip.white, \n        blank.lines.skip = blank.lines.skip, multi.line = FALSE, \n        comment.char = comment.char, allowEscapes = allowEscapes, \n        flush = flush, encoding = encoding, skipNul = skipNul)\n    nlines &lt;- length(data[[which.max(keep)]])\n    if (cols != length(data)) {\n        warning(\"cols = \", cols, \" != length(data) = \", length(data), \n            domain = NA)\n        cols &lt;- length(data)\n    }\n    if (is.logical(as.is)) {\n        as.is &lt;- rep_len(as.is, cols)\n    }\n    else if (is.numeric(as.is)) {\n        if (any(as.is &lt; 1 | as.is &gt; cols)) \n            stop(\"invalid numeric 'as.is' expression\")\n        i &lt;- rep.int(FALSE, cols)\n        i[as.is] &lt;- TRUE\n        as.is &lt;- i\n    }\n    else if (is.character(as.is)) {\n        i &lt;- match(as.is, col.names, 0L)\n        if (any(i &lt;= 0L)) \n            warning(\"not all columns named in 'as.is' exist\")\n        i &lt;- i[i &gt; 0L]\n        as.is &lt;- rep.int(FALSE, cols)\n        as.is[i] &lt;- TRUE\n    }\n    else if (length(as.is) != cols) \n        stop(gettextf(\"'as.is' has the wrong length %d  != cols = %d\", \n            length(as.is), cols), domain = NA)\n    do &lt;- keep & !known\n    if (rlabp) \n        do[1L] &lt;- FALSE\n    for (i in (1L:cols)[do]) {\n        data[[i]] &lt;- if (is.na(colClasses[i])) \n            type.convert(data[[i]], as.is = as.is[i], dec = dec, \n                numerals = numerals, na.strings = character(0L), \n                tryLogical = tryLogical)\n        else if (colClasses[i] == \"factor\") \n            as.factor(data[[i]])\n        else if (colClasses[i] == \"Date\") \n            as.Date(data[[i]])\n        else if (colClasses[i] == \"POSIXct\") \n            as.POSIXct(data[[i]])\n        else methods::as(data[[i]], colClasses[i])\n    }\n    compactRN &lt;- TRUE\n    if (missing(row.names)) {\n        if (rlabp) {\n            row.names &lt;- data[[1L]]\n            data &lt;- data[-1L]\n            keep &lt;- keep[-1L]\n            compactRN &lt;- FALSE\n        }\n        else row.names &lt;- .set_row_names(as.integer(nlines))\n    }\n    else if (is.null(row.names)) {\n        row.names &lt;- .set_row_names(as.integer(nlines))\n    }\n    else if (is.character(row.names)) {\n        compactRN &lt;- FALSE\n        if (length(row.names) == 1L) {\n            rowvar &lt;- (1L:cols)[match(col.names, row.names, 0L) == \n                1L]\n            row.names &lt;- data[[rowvar]]\n            data &lt;- data[-rowvar]\n            keep &lt;- keep[-rowvar]\n        }\n    }\n    else if (is.numeric(row.names) && length(row.names) == 1L) {\n        compactRN &lt;- FALSE\n        rlabp &lt;- row.names\n        row.names &lt;- data[[rlabp]]\n        data &lt;- data[-rlabp]\n        keep &lt;- keep[-rlabp]\n    }\n    else stop(\"invalid 'row.names' specification\")\n    data &lt;- data[keep]\n    if (is.object(row.names) || !(is.integer(row.names))) \n        row.names &lt;- as.character(row.names)\n    if (!compactRN) {\n        if (length(row.names) != nlines) \n            stop(\"invalid 'row.names' length\")\n        if (anyDuplicated(row.names)) \n            stop(\"duplicate 'row.names' are not allowed\")\n        if (anyNA(row.names)) \n            stop(\"missing values in 'row.names' are not allowed\")\n    }\n    class(data) &lt;- \"data.frame\"\n    attr(data, \"row.names\") &lt;- row.names\n    data\n}\n&lt;bytecode: 0x1364f78b0&gt;\n&lt;environment: namespace:utils&gt;\n\n\nTo start with, the code is quite long. This should really highlight the power of functions in R. Instead of having to write all of this code every time you want to read in a table, you can simply call the read.table function and it will execute all of that code for you.\nIf you scroll to the beginning, you can see that the code begins with a call of function, which indicates that this is a function definition. This is followed by the arguments that the function takes, which are listed in parentheses (). In this case, the read.table function takes several arguments, such as file, header, and sep.\nThe code inside the curly braces {} is the body of the function, which contains the code and control flow statements that will be executed when the function is called.\n\nCustom functions\nR allows you to create your own custom functions using the same syntax. To create a function in R, you use the function keyword. For example, here is a simple function that takes two numbers as input, calculates the sum and outputs a log transformation:\n\nlog_sum &lt;- function(x, y) {\n  sum &lt;- sum(x,y)\n  logsum &lt;- log(sum)\n  return(logsum)\n}\n\nIn this example, we define a function called log_sum that takes two arguments, x and y. The body of the function calculates the sum of x and y and then transforms it using the log function.\nThe return() function is used to return the value of logsum when the function is called. If a return statement is not included, the function will just return the value of the last expression.\nYou can call this function by passing two numbers as arguments:\n\nlog_sum(3, 5)\n\n[1] 2.079442\n\n\nIf we need to perform this calculation multiple times with different numbers, we can simply call the log_sum function with different arguments instead of writing the same code over and over again.\nWe can add default values to the function arguments. This allows us to call the function without providing values for those arguments, and the default values will be used instead. For example:\n\nlog_sum &lt;- function(x, y, base = exp(1)) {\n  sum &lt;- sum(x,y)\n  logsum &lt;- log(sum, base = base)\n  return(logsum)\n}\n\nIn this example, we added a new argument called base with a default value of exp(1), which is the natural logarithm base. If we call the function without providing a value for base, it will use the default value:\n\nlog_sum(3, 5)\n\n[1] 2.079442\n\n\nIf we want to use a different base for the logarithm, we can provide a value for the base argument when calling the function:\n\nlog_sum(3, 5, base = 10)\n\n[1] 0.90309\n\n\nAnother useful feature of functions in R is that they can return multiple values as a list. For example:\n\nlog_sum &lt;- function(x, y, base = exp(1)) {\n  sum &lt;- x + y\n  logsum &lt;- log(sum, base = base)\n  return(list(sum = sum, logsum = logsum))\n}\n\nIn this example, the log_sum function returns a list containing both the sum and the log of the sum. You can access these values using the $ operator:\n\nresult &lt;- log_sum(3, 5)\nresult$sum\n\n[1] 8\n\nresult$logsum\n\n[1] 2.079442\n\n\nFunctions are a fundamental part of programming in R. They allow you to write reusable code that can be easily maintained and shared with others. They also help to make your code more organised and easier to read.\n\n\n Challenge:\n\nWrite a function called qPCR_analysis that performs all of the steps we used in the first session.\n\nLoad the data from “data/qpcr_results.xlsx” into a data frame.\nCalculate the delta_ct values for each sample.\nPerform a t-test to compare the delta_ct values between the two conditions.\nCalculate the fold change in gene expression between the treatment and control groups.\nPlot a boxplot of the delta_ct values for the control and treatment groups.\n\nThe function should take a data frame as an argument and return a list containing the t-test result and the fold change. It should also plot a boxplot of delta_ct values per condition.\n\n\n\n\nSolution. \n\n Solution:\n\n\nqPCR_analysis &lt;- function(qpcr_table) {\n  \n  # Calculate delta_ct values\n  qpcr_table$delta_ct &lt;- qpcr_table$ct_gene - qpcr_table$ct_ref\n  \n  # Plot boxplot in base R\n  boxplot(delta_ct ~ Condition, data = qpcr_table, main = \"Delta Ct values by condition\", ylab = \"Delta Ct\")\n  \n  # Perform t-test\n  t_test_result &lt;- t.test(delta_ct ~ Condition, data = qpcr_table, var.equal=TRUE)\n  \n  # Calculate fold change\n  mean_control &lt;- mean(qpcr_table$delta_ct[qpcr_table$Condition == \"Control\"])\n  mean_treatment &lt;- mean(qpcr_table$delta_ct[qpcr_table$Condition == \"Treatment\"])\n  delta_delta_ct &lt;- mean_treatment - mean_control\n  fold_change &lt;- 2^(-delta_delta_ct)\n  \n  return(list(t_test_result = t_test_result, fold_change = fold_change, boxplot = boxplot))\n}\n\n\n\n\n\nYou can call this function by passing a data frame containing the qPCR results:\n\n# Load the data\nlibrary(readxl)\nqpcr_result &lt;- read_excel(\"data/qpcr_data.xlsx\")\n\n# Call the qPCR_analysis function\nresults &lt;- qPCR_analysis(qpcr_result)\n\n\n\n\n\n\n\n# Access the p-value and fold change\npaste(\"The p-value is \", results$t_test_result$p.value, \" and the fold change is \", results$fold_change)\n\n[1] \"The p-value is  1.82070315127758e-08  and the fold change is  2.953652291879\"\n\n\nWe have now written a function that performs all of the steps of our qPCR analysis. This function can be reused for different datasets by simply passing a different data frame as an argument.\nLet’s load a second qPCR dataset to test our function:\n\n# Download the second dataset\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data2.xlsx\", destfile = \"data/qpcr_data2.xlsx\")\n\nlibrary(readxl)\nqpcr_table2 &lt;- read_excel(\"data/qpcr_data2.xlsx\")\n\n# Call the qPCR_analysis function\nresults2 &lt;- qPCR_analysis(qpcr_table2)\n\n\n\n\n\n\n\npaste(\"The p-value is \", results2$t_test_result$p.value, \" and the fold change is \", results2$fold_change)\n\n[1] \"The p-value is  0.207646591718013  and the fold change is  0.726986258660155\"\n\n\nHow easy was that! This is the power of functions in R."
  },
  {
    "objectID": "02-Programming.html#reproducible-r-scripts",
    "href": "02-Programming.html#reproducible-r-scripts",
    "title": "Programming in R",
    "section": "Reproducible R scripts",
    "text": "Reproducible R scripts\nR scripts are plain text files that contain R code. They can be created and edited in any text editor, but using an environment like RStudio makes it easier to write and run your code.\nSaving your code in an R script allows you to keep a record of your analysis and makes it easier to reproduce your results. You can also share your R scripts with others, allowing them to run the same code on different data.\n\nRunning R scripts\nR scripts can be run interactively in RStudio by clicking the “Source” button or by using the source() function in the console. For example, if you have an R script called analysis.R in your working directory, you can run it with the following command:\n\n## Example, don't run this\nsource(\"analysis.R\")\n\nR scripts can also be run from the Windows, Mac or Linux command line. This is useful for several reasons:\n\nRun R scripts without opening RStudio\nRun R scripts with arguments (see below)\nInclude R scripts in larger workflows or pipelines\nRun R scripts on a remote server or cluster\nRun multiple R analyses at once\n\nTo run an R script from the command line, you need to open a Terminal window. Most computers have a Terminal app installed. RStudio has an inbuilt Terminal, you can find it next to the Console tab.\n\nConsole is where you can run R commands interactively.\nTerminal is where you can run command line commands on your computer or server.\n\nTo run an R script on the command line, use the Rscript command:\n\n## Example, don't run this \nRscript analysis.R\n\n\n\nExample R Script\nDownload the R script below and open it in RStudio for reading.\n\ndir.create(\"scripts\")\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/scripts/qPCR_analysis.R\", destfile = \"scripts/qpcr_analysis.R\")\n\n\n\n Discussion:\n\n\nWhat does the script do?\nWhat are the inputs and outputs of the script?\nWhere are the output files saved?\nWhat are the advantages of using an R script instead of running code interactively in the console?\n\n\n\nTry running this script in RStudio and from the command line. Make sure you are in your working directory.\n\nRscript scripts/qpcr_analysis.R\n\n\nWhat happens when you run the R Script?\nWhere does the output appear?\n\n\n\nArguments\nAt the moment our script is not very flexible. It is hard coded to read in a specific file and save the output to a specific location.\nWe can make our script more flexible by using arguments. Arguments allow us to specify the input and output files on the command line instead of in the script. This way, we can change them easily without ever having to edit the code e.g.\n\n## These are just examples, don't run them yet.\nRscript qPCR_analysis.R data/qpcr_results.xlsx qpcr_plot_exp1.png\n\nOR\n\nRscript qPCR_analysis.R data/qpcr_results2.xlsx qpcr_plot_exp2.png\n\nR interprets everything after the script name as an argument to the script. In the example above, data/qpcr_results.xlsx is the input file containing the qPCR results and qpcr_plot.png is the name of the output file where the plot will be saved.\nWe need to make a few changes to our script for R to accept these argument. We can use the built-in function commandArgs() to access the arguments passed to the script from the command line. You can use this function to read in the input and output file paths as arguments. For example:\n\nargs &lt;- commandArgs(trailingOnly = TRUE) ## trailingOnly = TRUE means that only the arguments after the script name will be returned\ninput_file &lt;- args[1] # The first argument will be the input file path\noutput_file &lt;- args[2] # The second argument will be the output file path\n\nThis code will read in the first and second arguments passed to the script and store them in the input_file and output_file variables, respectively. You can then use these variables in your code to read in the data and save the plot.\n\n\n Challenge:\n\nModify the qPCR_analysis.R script to use the input and output file paths as arguments.\nHINTS\n\nUse the commandArgs() function to read in the arguments from the command line.\nReplace the hardcoded input file name with the input_file variable.\nReplace the hardcoded output file name with the output_file variable to save the plot.\n\n\n\n\n\nSolution. \n\n Solution:\n\n\nlibrary(readxl)\n\nargs &lt;- commandArgs(trailingOnly = TRUE) ## trailingOnly = TRUE means that only the arguments after the script name will be returned\ninput_file &lt;- args[1]\noutput_file &lt;- args[2]\n\n# Read in the data\nqpcr_data &lt;- read_excel(input_file)\n\n# Function to perform qPCR analysis\nqPCR_analysis &lt;- function(qpcr_table,plot_file) {\n  \n  # Calculate delta_ct values\n  qpcr_table$delta_ct &lt;- qpcr_table$ct_gene - qpcr_table$ct_ref\n  \n  # Perform t-test\n  t_test_result &lt;- t.test(delta_ct ~ Condition, data = qpcr_table, var.equal=TRUE)\n  \n  # Calculate fold change\n  mean_control &lt;- mean(qpcr_table$delta_ct[qpcr_table$Condition == \"Control\"])\n  mean_treatment &lt;- mean(qpcr_table$delta_ct[qpcr_table$Condition == \"Treatment\"])\n  delta_delta_ct &lt;- mean_treatment - mean_control\n  fold_change &lt;- 2^(-delta_delta_ct)\n  \n  # Save boxplot as a PDF\n  png(plot_file)\n  boxplot(delta_ct ~ Condition, \n          data = qpcr_table, \n          main = \"Delta Ct values by condition\", \n          ylab = \"Delta Ct\",\n          sub = paste(\"Fold change:\", round(fold_change, 2), \n                      \"p-value:\", round(t_test_result$p.value, 4))\n          )\n  dev.off()\n}\n\nqPCR_analysis(qpcr_data, output_file)\n\n\n\n\n\nTry running the modified script from the terminal window specifying the input and output file names:\n\nRscript scripts/qPCR_analysis.R data/qpcr_data.xlsx qPCR_plot_exp1.png\n\nNow run the script on our second qPCR dataset:\n\nRscript scripts/qPCR_analysis.R data/qpcr_data2.xlsx qPCR_plot_exp2.png\n\n\n\nCommenting and formatting\nWhen writing R scripts, it’s important to use good commenting and formatting practices. This makes your code easier to read and understand, both for yourself and for others who may be reading your code in the future.\nSome quick tips:\n\nUse comments to explain what your code is doing and why. This is especially important for complex code or code that may not be immediately obvious.\nUse consistent indentation and spacing to make your code more readable. This can help to visually separate different blocks of code and make it easier to follow the flow of the script.\nUse meaningful variable names that describe the purpose of the variable.\nBreak up long lines of code into multiple lines to improve readability. This can help to prevent horizontal scrolling and make it easier to read the code.\nUse functions to break up your code into smaller, more manageable pieces.\n\nLater on we will cover some tools that can help with formatting your code, such as the styler package and the formatR package.\n\n\n Challenge:\n\nSee if you can add more customisable arguments to the qPCR_analysis.R script. Be sure to comment your edits and use good formatting practices.\nSOME IDEAS\n\nAllow the user to specify the title of the plot as an argument.\nAllow the user to specify the plot file format to be either png or pdf as an argument (hint: use an if statement)."
  },
  {
    "objectID": "02-Programming.html#summary",
    "href": "02-Programming.html#summary",
    "title": "Programming in R",
    "section": "Summary",
    "text": "Summary\nUsing scripts and programmable functions is a really powerful way to perform your data analysis. Programming languages provide automation, flexibility and reproducibility.\n\n\n Resources\n\n\nThe Discdown R Programming book is a comprehensive resource introducing R datatypes, syntax and programming concepts. It is available online for free.\n\n\n\n\n\n Key points\n\n\nR is a powerful programming language that allows you to automate tasks and write reproducible code.\nControl flow functions like if statements and for loops allow you to write code that can adapt to different situations and perform complex tasks.\nFunctions are reusable blocks of code that perform a specific task.\nR scripts allow you to save and share your code, making analyses reproducible and customisable."
  },
  {
    "objectID": "02-HW.html",
    "href": "02-HW.html",
    "title": "Homework Task",
    "section": "",
    "text": "Write an R script to perform a data analysis task"
  },
  {
    "objectID": "02-HW.html#task",
    "href": "02-HW.html#task",
    "title": "Homework Task",
    "section": "Task",
    "text": "Task\nWrite an R script to perform a data analysis task. Your script should do the following:\n\nImport a dataset as a data frame\nPerform exploratory data analysis\n\nSummarise the dataset\nCalculate summary statistics of variables (e.g. mean)\n\nPlot the data (e.g. scatter plot, histogram, boxplot)\nSave the plot to a PNG file\n\nAdditionally, you could try to:\n\nRun a statistical test on the data\nWrite a custom function to use in your script e.g.\n\nTo calculate a specific statistic\nTo perform a specific data manipulation task\nTo create a specific type of plot\n\nParameterise your script by adding command line arguments\n\nIf you need help with this task:\n\nEmail the Bioinformatics Core team, we’re happy to help!\nCome to a drop in session. We run these monthly.\nSearch online, there is an abundance of R forums, guides and videos\nUse AI. It’s pretty good at coding and can be a great way to learn. Just make sure you understand the code it generates and don’t just copy and paste without thinking about it!"
  },
  {
    "objectID": "02-HW.html#data",
    "href": "02-HW.html#data",
    "title": "Homework Task",
    "section": "Data",
    "text": "Data\nYou can use any dataset you like for this task. It would be best to use your own research data if possible. Building your programming skills around your own data is a great way to learn R. Real world data can also be messy and this will give you a more realistic experience of data analysis.\nIf you don’t have your own data, you can use the case study below, find a dataset online or even simulate your own dataset.\n\nPublished data\nYou could use a dataset from a published paper. This is a great way to practice analysing real data interpreting scientific results. You can usually find datasets in the supplementary materials of papers.\nAlternatively, you can use a dataset related to a specfic hobby or interest you might have. Choose something that motivates you!\nKaggle has an abundance of public datasets that you can use for this task at https://www.kaggle.com/datasets e.g.\n\nPremier league football\nCOVID-19 case outcomes\nMovie ratings and revenues\nCensus data\n\n\n\nSimulated data\nThe code below shows how to simulate a fairly generic dataset in R. You could modify the conditions and values to look like a more familiar dataset for your research e.g\n\nGene expression levels across different conditions\nCell counts across different time points\nFluorescence intensity measurements across different samples\n\n\nset.seed(123) # for reproducibility\nn &lt;- 100\n\nsim_data &lt;- data.frame(\n  Condition = c(rep(\"Control\",n/2), rep(\"Treatment\",n/2)),\n  Value = c(rnorm(n/2, mean = 50, sd = 10),rnorm(n/2, mean = 60, sd = 10))\n)"
  },
  {
    "objectID": "02-HW.html#case-study-enhancing-memory-with-neurotrophic-factors",
    "href": "02-HW.html#case-study-enhancing-memory-with-neurotrophic-factors",
    "title": "Homework Task",
    "section": "Case Study: Enhancing Memory with Neurotrophic Factors",
    "text": "Case Study: Enhancing Memory with Neurotrophic Factors\nIn the study of learning and memory, researchers focus on how neurons strengthen their connections, a process called Long-Term Potentiation (LTP). A key player in this process is BDNF (Brain-Derived Neurotrophic Factor), a protein that acts like “fertilizer” for neurons, promoting the growth of dendritic spines, the tiny protrusions on neurons where synapses are formed. More spines generally correlate with a higher capacity for memory storage.\nResearchers are investigating whether a synthetic mimetic of BDNF (called “NeuroBoost”) increases the density of dendritic spines.\n\nExperimental setup:\n\n16 samples (primary neuronal cultures)\n\n8 Control\n8 Treated with NeuroBoost\n\n\nUsing a confocal microscope, a researcher selects a dendrite and counts the number of spines per 10 micrometers (\\(\\mu m\\)) of length. There are 16 independent batches of neurons derived from different embryos. For each batch, the researcher images 3 different neurons to account for the fact that some neurons in a dish are naturally more “branchy” than others.\nThe dataset can be downloaded from here: https://bifx-core3.bio.ed.ac.uk/training/DSB/data/spine_data.csv\n\nhead(spine_data)\n\n  Batch_ID Treatment Neuron_1 Neuron_2 Neuron_3\n1  Batch_1   Control        6        7        7\n2  Batch_2   Control        7        2        7\n3  Batch_3   Control        2        6        8\n4  Batch_4   Control        5        7        5\n5  Batch_5   Control        7        3        7\n6  Batch_6   Control        5        7        7\n\n\nThere are 3 neurons per batch. The neurons within a batch are not biologically independent because they come from the same dish and are influenced by the same microenvironment. Therefore, you cannot treat each neuron as an independent sample. Instead, you should average the 3 neurons to get a single value for each batch, which represents one independent measurement of spine density for that batch. The 16 batches of neurons are the independent samples in this experiment.\n\n\n Hints\n\n\nWhat file format is the data in? Which function will you use to import the data?\nLook into the rowMeans() function to calculate the average spine density for each batch.\nUse a t-test to compare the mean spine density between the Control and NeuroBoost groups.\nCreate a boxplot to visualize the distribution of spine densities for each treatment group."
  },
  {
    "objectID": "01-start.html",
    "href": "01-start.html",
    "title": "Introduction to RStudio",
    "section": "",
    "text": "We recommend using RStudio for this workshop. RStudio is an Integrated Development Environment (IDE) for R. It can be accessed in several ways."
  },
  {
    "objectID": "01-start.html#using-rstudio",
    "href": "01-start.html#using-rstudio",
    "title": "Introduction to RStudio",
    "section": "Using RStudio",
    "text": "Using RStudio\nA comprehensive RStudio user guide is available here.\n\n\nThe are 4 main panes, each with several tabs:\n\nConsole (bottom left)\n\nHere you can type commands into R\nAdditional tabs may include a terminal and script outputs\n\nSource (top left)\n\nOpen and view files\nThese can be raw txt, scripts or markdown\n\nEnvironments (top right)\n\nObjects you have stored\nCommands you have typed\nAdditional tabs for version control, database and website building…\n\nOutput (bottom right)\n\nSystem files (on the computer/server you are working on)\nOutput from plots or applications\nPackages available\nHelp pages\n\n\n\n\n\n\n\nYou can customise the appearance of RStudio under the menu option: Tools -&gt; Global Options…\n\nSetting up a new project\nThere is a drop-down project menu at the top right of RStudio. Click this, select “New Project…” and create one in a new directory. Make sure you have write permission for the directory you choose.\nOnce you have done this, this will be your working directory. Files will be saved (or loaded from) here by default unless you specify a full path. You can change your working directory under the session menu at the top.\nUsing Rstudio has the advantage that everything you do can be saved between RStudio sessions."
  },
  {
    "objectID": "01-start.html#working-in-rstudio",
    "href": "01-start.html#working-in-rstudio",
    "title": "Introduction to RStudio",
    "section": "Working in RStudio",
    "text": "Working in RStudio\nYou can work in 3 different ways in RStudio.\n\nUse the console to run commands.\nCreate a new R script to save your commands as you go.\nCreate a markdown file to generate web pages or pdf documents from your analyses.\n\nCommands can be typed directly into the console, but in order to keep track it’s best to write them into a script and save your progress as you go. You can open a new R script under the File menu at the top left of RStudio."
  },
  {
    "objectID": "01-start.html#running-commands",
    "href": "01-start.html#running-commands",
    "title": "Introduction to RStudio",
    "section": "Running commands",
    "text": "Running commands\nTo run commands directly from your script:\n\nPlace the cursor on the line of code you want to run\nUse the run button above your script\nAlternatively, use the shortcut keys.\n\nAlt + Enter to keep the cursor on the same line\nCtrl + Enter to move to the next line"
  },
  {
    "objectID": "01-start.html#writing-commands",
    "href": "01-start.html#writing-commands",
    "title": "Introduction to RStudio",
    "section": "Writing commands",
    "text": "Writing commands\nAs you write commands, RStudio will try to help you by showing you the syntax of the function you are using and the arguments it takes.\nYou can also use the Tab key to autocomplete names of functions, objects and arguments as you type them.\nWhen using the console, the Up/Down arrow keys can be used to cycle through previously run commands."
  },
  {
    "objectID": "01-start.html#console",
    "href": "01-start.html#console",
    "title": "Introduction to RStudio",
    "section": "Console",
    "text": "Console\nIn the console you should always see a &gt; prompt. This shows that the console is ready to go.\nIf you can’t see this, R may still be working. There is a red Stop light at the top right of the console when a command is running. You can use this or the Esc key to kill a command if it is taking too long or you have made a mistake.\nIf you see a + instead of &gt;, R is waiting for more input. Sometimes this means you have typed the code wrong or forgotten to close a bracket or quotation. You can get back to the &gt; prompt by pressing Esc."
  },
  {
    "objectID": "01-start.html#installing-libraries",
    "href": "01-start.html#installing-libraries",
    "title": "Introduction to RStudio",
    "section": "Installing libraries",
    "text": "Installing libraries\nLibraries provide additional functions in R and can be downloaded from several sources:\n\nCRAN is the Comprehensive R Archive Network and hosts the majority of generic R packages.\nBioconductor is a repository of biology specific packages.\nThird party tools are often hosted on github.\n\nThe examples below show how to install packages from these different sources. You only need to install a package once, but you will need to load it with library every time you start a new R session:\n\n## EXAMPLE ONLY DO NOT RUN\n\n#install from CRAN with install.packages()\ninstall.packages(c(\"tidyverse\", \"ggthemes\"))\n\n#Example to install from bioconductor with BiocManager\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(c(\"DESeq2\",\"genomation\"))\n\nExample to install from github with the devtools package\ninstall.packages(\"devtools\")\ndevtools::install_github(\"thomasp85/patchwork\")\n\nTo load a specific package within an R session, use the library function:\n\nlibrary(tidyverse)\n\nWe will install packages as we move through this course. Each section begins with a list of packages required. We recommend you install these in advance as it can be time consuming and sometimes problematic.\n\n\n How to follow each course\n\n\nCreate a new project in RStudio\nInstall the required libraries\n\nOpen a new R script\nIt will be best to work with the tutorial and RStudio open together so you can easily switch between the two. Working on a wide split-screen or multiple desktops is the best setup.\nI recommend typing out most of the commands rather than copy-and-pasting if you want to learn. Remember you can use the Tab key to save yourself from endless typing!"
  },
  {
    "objectID": "02-IntroR.html",
    "href": "02-IntroR.html",
    "title": "Introduction to R",
    "section": "",
    "text": "What is R?\nUnderstand R datatypes and classes\nUnderstand how to use functions in base R\nImport datasets into R\nInspect and format a dataset\nCreate basic graphics\nRun statistical tests"
  },
  {
    "objectID": "02-IntroR.html#what-is-r",
    "href": "02-IntroR.html#what-is-r",
    "title": "Introduction to R",
    "section": "What is R?",
    "text": "What is R?\nR is an extremely powerful programming language for data science, statistical analysis and data visualisation. It is favoured by biologists due to its extensive library of packages for bioinformatics and genomic analysis. In this lesson you will learn how to program and interact with data in R. We will cover the basics of the R syntax, using its built in packages (base R)."
  },
  {
    "objectID": "02-IntroR.html#why-is-r-useful",
    "href": "02-IntroR.html#why-is-r-useful",
    "title": "Introduction to R",
    "section": "Why is R useful?",
    "text": "Why is R useful?\n\nIt’s free! open source software.\nIt’s Powerful. There are many libraries for application specific tasks.\n\nBioconductor is a repository for bioinformatics R software.\nTidyverse is a suite of packages for data science with a shared philosophy for storing, manipulating and visualising data.\n\nPresentation quality graphics\n\nSave as a png, pdf or svg for use in publications and presentations.\n\nGenerate reproducible and persistent results\n\nR commands and analyses can be saved for reproducible and persistent analyses.\nCreate automated scripts to replicate analysis on different datasets.\n\nRStudio provides an interactive environment for working in R.\nR markdown can generate documents to present your analyses as reports.\nShiny can produce interactive applications for exploratory data analysis."
  },
  {
    "objectID": "02-IntroR.html#working-directory",
    "href": "02-IntroR.html#working-directory",
    "title": "Introduction to R",
    "section": "Working directory",
    "text": "Working directory\nThis is the directory used to store your data and results. This is where R will look for files to read in and where it will save any output files. You can check your current working directory with the getwd() function.\n\ngetwd()\n\nIf you want to change the working directory you can use setwd(\"/path/to/new_directory\") or use the session menu in RStudio."
  },
  {
    "objectID": "02-IntroR.html#data-types",
    "href": "02-IntroR.html#data-types",
    "title": "Introduction to R",
    "section": "Data Types",
    "text": "Data Types\nValues in R are assigned a data type which tells R how to interpret them. Some common data types are:\n\nnumeric: Numbers\ncharacter: Strings of text\nfactor: Labels for categorical data (e.g. species, sex)\nlogical: TRUE or FALSE values"
  },
  {
    "objectID": "02-IntroR.html#data-structures",
    "href": "02-IntroR.html#data-structures",
    "title": "Introduction to R",
    "section": "Data Structures",
    "text": "Data Structures\nR uses different data structures to organise data. Common structures are shown below.\n\nVector\n\nA collection of values of one data type\nEquivalent to a column in a table\nItems in the vector can be named\nE.g. A collection of recorded mouse weights\n\n\n## numeric vector\nc(12.3, 15.6, 9.8, 7.4) \n\n[1] 12.3 15.6  9.8  7.4\n\n## A named vector\nc(M1=12.3, M2=15.6, M3=9.8, M4=7.4)\n\n  M1   M2   M3   M4 \n12.3 15.6  9.8  7.4 \n\n\n\n\nData Frame\n\nA table\nEssentially a collection of vectors as columns\nColumns can be different data types\nColumns must have the same length\nE.g. A table of mouse weights with columns (Mouse_ID (character), Sex (factor), Weight (numeric))\n\n\ndata.frame(\n  Mouse_ID = c(\"M1\", \"M2\", \"M3\"),\n  Sex = factor(c(\"M\", \"F\", \"F\")), # use the factor function to tell R that this is categorical data\n  Weight = c(12.3, 15.6, 9.8)\n)\n\n  Mouse_ID Sex Weight\n1       M1   M   12.3\n2       M2   F   15.6\n3       M3   F    9.8\n\n\n\n\nMatrix\n\nA table where all values are related and of the same data type\nCommonly used for correlation and heatmap analysis\nE.g. A table of RNA-seq expression levels where each row is a gene and each column is a different sample.\n\n\nmatrix &lt;- matrix(c(5, 2, 3, 8, 7, 4), nrow=2)\nrownames(matrix) &lt;- c(\"GeneA\", \"GeneB\")\ncolnames(matrix) &lt;- c(\"Sample1\", \"Sample2\", \"Sample3\")\n\nmatrix\n\n      Sample1 Sample2 Sample3\nGeneA       5       3       7\nGeneB       2       8       4\n\n\n\n\nList\n\nLists are collections of R objects.\nEach item in the list has a unique index or name.\nA list can contain items of different object types and classes (e.g single values, vectors, data frames, matrices, other lists…).\nE.g. A list containing a data frame of sample information, a matrix of expression values and a vector of gene names.\n\n\nlist(\n  sample_info = data.frame(SampleID=c(\"Sample1\",\"Sample2\"), Condition=factor(c(\"Control\",\"Treated\"))), # data frame\n  expression_matrix = matrix(c(5,2,3,8), nrow=2), # matrix of expression values\n  gene_names = c(\"GeneA\", \"GeneB\") # vector\n)\n\n$sample_info\n  SampleID Condition\n1  Sample1   Control\n2  Sample2   Treated\n\n$expression_matrix\n     [,1] [,2]\n[1,]    5    3\n[2,]    2    8\n\n$gene_names\n[1] \"GeneA\" \"GeneB\""
  },
  {
    "objectID": "02-IntroR.html#r-syntax",
    "href": "02-IntroR.html#r-syntax",
    "title": "Introduction to R",
    "section": "R Syntax",
    "text": "R Syntax\nR is a functional programming language:\n\nNearly every command is the name of a function followed by parentheses.\nThe inputs to a function, including different options, are placed in the brackets.\nYou can use the Tab key to see the options available or use the help documentation for each function.\n\nTypical command structure:\n\nfunction_name(data, options, moreOptions)\n\nLet’s run a function on a real data set. The cars data set is built into base R. We can look at it by typing its name.\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\n\nWe can see that this is a table of values. If we run the class function we will see that R recognises this as a data.frame.\n\nclass(cars)\n\n[1] \"data.frame\"\n\n\nNow let’s run a more useful function. The plot function in R is used for making basic graphs. It also has additional arguments which can be altered to change its behaviour. Try plotting the cars data.\n\n## Use the options within the plot function to customise the output\nplot(cars, xlab = \"Car Speed (mph)\", ylab = \"Stopping Distance (ft)\")\n\n\n\n\n\n\n\n\nNot all functions need arguments. For instance, the getwd function which returns the path of your working directory.\n\ngetwd()"
  },
  {
    "objectID": "02-IntroR.html#storing-objects",
    "href": "02-IntroR.html#storing-objects",
    "title": "Introduction to R",
    "section": "Storing objects",
    "text": "Storing objects\nWe can create objects in R to store data or the output of functions. This is useful for saving data that we want to use later on, or for storing intermediate steps in an analysis.\nWe can use the = sign or &lt;- to store the output of a function as an object.\n\n## These statements are identical\nresult = function_name(data, options, moreOptions)\nresult &lt;- function_name(data, options, moreOptions)\n\nTry storing the output of the summary function on the cars data set. You will see the object sum_cars appear in your Environment tab in RStudio.\n\nsum_cars = summary(cars)\n\nTo see what this object holds, just type its name.\n\nsum_cars\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "02-IntroR.html#getting-help",
    "href": "02-IntroR.html#getting-help",
    "title": "Introduction to R",
    "section": "Getting help",
    "text": "Getting help\nR has extensive built in help documentation. You can access this using the help function. The command below provides the help page for the function read.table\n\nhelp(read.table)\n\nWe can also search the help documentation using help.search. Let’s see if we can find a function for running a t-test.\n\nhelp.search(\"t test\")\n\nNOTE quotes are required around strings of text. You do not need to use quotes when referring to names of R data objects or functions.\nThere is a short cut for help, ?, which shows the help page for a function.\n\n# same as help(read.table)\n?read.table\n\n?? searches for help pages on functions, same as help.search(“phrase”)\n\n# same as help.search(\"t test\")\n??\"t test\"\n\nYou can also use the Help tab in RStudio to search for help on functions, or search online.\n\n\n Key points\n\n\nData types: Understand different data types (numeric, character, factor, logical)\nR objects: Understand different ways to structure data in R (vectors, dataframes, matrices, lists). There are several other types of R object.\nFunctions: Code in R is run within functions.\nHelp: Use the help features to find out how a function works."
  },
  {
    "objectID": "02-IntroR.html#getting-data-into-r",
    "href": "02-IntroR.html#getting-data-into-r",
    "title": "Introduction to R",
    "section": "Getting data into R",
    "text": "Getting data into R\nGetting data into R is often the first step in any analysis.\nIt is possible to create a vector of data by typing directly into R using the function c. The c stands for combine and can be used to combine values into a vector.\n\nx   &lt;-  c(1,2,3,4,5)\n\nThis creates a vector named ‘x’ which stores the numbers 1 through to 5.\nYou can see what is in an object at any time by typing its name:\n\nx\n\n[1] 1 2 3 4 5\n\n\nCharacter values need to be quoted, otherwise R will look for a data object of that name.\n\n## This produces an error because R is looking for objects called Monday, Tuesday etc. which do not exist.\ndaysofweek &lt;- c(Monday, Tuesday, Wednesday, Thursday, Friday)\n\n\n## This works\ndaysofweek &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\")\n\nYou can create data frames from vectors using the data.frame function:\n\ntable &lt;- data.frame(Index = x, Day = daysofweek)\n\ntable\n\n  Index       Day\n1     1    Monday\n2     2   Tuesday\n3     3 Wednesday\n4     4  Thursday\n5     5    Friday\n\n\nUsually however, you will want to input data from a file. You can read files on your computer or from a URL. Use the read.table function to read in the table hosted at the URL below.\n\nread.table(\"http://bifx-core3.bio.ed.ac.uk/data.tsv\")\n\nR reads this table as a data.frame object and prints it to the R console by default. To save the table, we need to assign it to an object.\n\nmydata  &lt;- read.table(\"http://bifx-core3.bio.ed.ac.uk/data.tsv\")\n\nHere, mydata is an object name and the syntax &lt;- assigns the output of the function to it. Remember you can also use =.\nR stores mydata as a data frame, containing multiple vectors. We can check the class of our object using the class() function. The Environment tab in RStudio can also be used to explore objects and their properties.\n\nclass(mydata)\n\n[1] \"data.frame\"\n\n\nWe can look at our table by typing its name, but this prints a lot of rows. Using the head() function will only print the first few lines;\n\nhead(mydata, n=5)\n\n  V1 V2 V3 V4 V5\n1  A  B  C  D  E\n2  1  4  1  1  1\n3  2  5  1  1  2\n4  2  5  1  1  2\n5  3  6  1  2  3\n\n\nYou can also use the View() command to open data frames in the file pane.\nHmmm, something isn’t right with our rows here…\nBy default the read.table function assumes certain things from the file\n\nThe file is a plain text file (there are separate functions to read excel files etc.)\nColumns are separated by any number of tabs or spaces\nThere are the same number of data points in each column\nThere is no header row (labels for the columns)\nThere is no column with names for the rows\n\nIf any of these are FALSE, then we need to give that information to the function. If it has a header column use the ‘header=TRUE’ argument.\n\nmydata &lt;- read.table(\"http://bifx-core3.bio.ed.ac.uk/data.tsv\", header=TRUE)  \n\n# Note that header=T will also work here. TRUE and FALSE can be abbreviated to T and F in R.\n\nNote the comma between different parts of the functions arguments.\nThis overwrites our previous data frame mydata with the correctly formatted one. Let’s look at the first 5 rows again.\n\nhead(mydata, n=5)\n\n  A B C D E\n1 1 4 1 1 1\n2 2 5 1 1 2\n3 2 5 1 1 2\n4 3 6 1 2 3\n5 3 6 1 2 3\n\n\nNow we can see that the first row contains the column labels (A, B, C, D, E). R has automatically assigned default row names (1, 2, 3 etc.)\n\nOther options for read.table\nUse sep = to define how columns are separated in your input file. This file uses the tab character which we can write as “\\t”.\n\nmydata  &lt;- read.table(\"http://bifx-core3.bio.ed.ac.uk/data.tsv\", header = T, sep = \"\\t\")\n\nBy default, read.table assumes columns are separated by any amount of white space (space or tabs). This can lead to problems if some of your columns have missing values, so it is good practice to always give a sep argument.\nIf your data has missing values you can use fill = TRUE.\n\nmydata  &lt;- read.table(\"http://bifx-core3.bio.ed.ac.uk/data.tsv\", header = T, sep = \"\\t\", fill = T)\n\nThis tells R to fill empty spaces in columns with the ‘NA’ character.\nAs this is such a common task there are functions identical to read.table but with different default settings. e.g. read.delim and read.csv. Check out the help pages for each of these.\n\n\nImporting Datasets\nIn the Environment pane in RStudio there is a button called Import Dataset. This can make importing data much easier and calls the read.* set of functions for you. The command used will be displayed on the console. Make sure you save this code so that you can easily re-run the analysis later.\nNote that you need to have the file on the computer to use this button."
  },
  {
    "objectID": "02-IntroR.html#inspect-and-summarise-data",
    "href": "02-IntroR.html#inspect-and-summarise-data",
    "title": "Introduction to R",
    "section": "Inspect and summarise data",
    "text": "Inspect and summarise data\nLet’s use some simple functions to inspect and summarise our data.\n\nstr(mydata) # Shows the structure of a data frame and the data types of each column\n\n'data.frame':   27 obs. of  5 variables:\n $ A: int  1 2 2 3 3 3 3 3 4 4 ...\n $ B: int  4 5 5 6 6 6 6 6 7 7 ...\n $ C: int  1 1 1 1 1 1 1 1 1 1 ...\n $ D: int  1 1 1 2 2 2 2 2 2 2 ...\n $ E: int  1 2 2 3 3 4 3 3 4 4 ...\n\n\n\nsummary(mydata) # Summarises the values in each column \n\n       A               B                C               D        \n Min.   :1.000   Min.   : 4.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:3.000   1st Qu.: 6.000   1st Qu.:1.000   1st Qu.:2.000  \n Median :4.000   Median : 7.000   Median :1.000   Median :3.000  \n Mean   :4.296   Mean   : 7.296   Mean   :1.778   Mean   :3.333  \n 3rd Qu.:5.000   3rd Qu.: 8.000   3rd Qu.:2.000   3rd Qu.:4.000  \n Max.   :8.000   Max.   :11.000   Max.   :5.000   Max.   :9.000  \n       E        \n Min.   :1.000  \n 1st Qu.:3.500  \n Median :4.000  \n Mean   :4.407  \n 3rd Qu.:5.000  \n Max.   :8.000  \n\n\nIndividual columns in a data frame can be accessed using the $ sign (mydata$A mydata$B etc.)\n\nmydata$A # Prints all values in column A\n\n [1] 1 2 2 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 6 6 6 7 7 8\n\n\n\nsummary(mydata$A) # Summary information for column A only\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.000   4.000   4.296   5.000   8.000 \n\n\n\nmean(mydata$A) # Mean of column A\n\n[1] 4.296296\n\n\nTry some other summary functions like mean, median, min and max."
  },
  {
    "objectID": "02-IntroR.html#square-bracket-notation",
    "href": "02-IntroR.html#square-bracket-notation",
    "title": "Introduction to R",
    "section": "Square bracket notation",
    "text": "Square bracket notation\nWe can access specific rows, columns and cells within a data frame using square brackets: TABLE[ROW,COLUMN]. You can experiment with this notation by trying out the following commands.\n\n## Print the value in the first column of the first row\nmydata[1,1]\n\n## Use blanks to print an entire row or column\nmydata[2,]\nmydata[,3]\n\n## You can select multiple rows and columns with ranges (:) or the c() function\n## E.g. Print the first 5 rows of columns 3 and 5\nmydata[1:5,c(3,5)]\n\n## You can also use row or column names instead of numbers\nmydata[,\"B\"]\n\n## You can select rows or columns based on certain criteria (subsetting).\n## E.g. Select all rows where B is greater than 7\nmydata[mydata$B &gt; 7,]"
  },
  {
    "objectID": "02-IntroR.html#ordering-data",
    "href": "02-IntroR.html#ordering-data",
    "title": "Introduction to R",
    "section": "Ordering data",
    "text": "Ordering data\nThe order function can be used to sort data frames by a specific column.\n\norder(mydata$B) # Returns the row numbers in the sorted order of column B\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27\n\n# We can use this in the row index position to sort the entire data frame by column B\nmydata[order(mydata$B), ]\n\n   A  B C D E\n1  1  4 1 1 1\n2  2  5 1 1 2\n3  2  5 1 1 2\n4  3  6 1 2 3\n5  3  6 1 2 3\n6  3  6 1 2 4\n7  3  6 1 2 3\n8  3  6 1 2 3\n9  4  7 1 2 4\n10 4  7 1 2 4\n11 4  7 1 2 4\n12 4  7 1 2 5\n13 4  7 1 2 5\n14 4  7 1 3 4\n15 4  7 1 3 4\n16 4  7 1 3 4\n17 4  7 2 3 4\n18 5  8 2 3 5\n19 5  8 2 4 5\n20 5  8 2 4 5\n21 5  8 2 4 5\n22 6  9 3 5 6\n23 6  9 3 5 6\n24 6  9 3 6 6\n25 7 10 4 7 7\n26 7 10 4 8 7\n27 8 11 5 9 8\n\n\n\n\n Challenge:\n\n\nSee if you can do the following:\n\nSelect the 11th value in the third column\nSelect all rows where D equals 4 (hint; use ‘==’)\nSelect rows where B has its maximum value (hint: use the max function)\nSelect even numbered rows only (hint: take a look at the seq function ‘?seq()’)\nSelect columns A, C and E\nSort table by decreasing order of column B (hint: look at the options in the order function)\n\n\n\n\n\nSolution. \n\n Solution:\n\n\nSelect row 11, column 3\n\n\nmydata[11,3]\n\n[1] 1\n\n\n\nSelect rows where D 3 equals 4\n\n\nmydata[mydata$D == 4,] \n\n   A B C D E\n19 5 8 2 4 5\n20 5 8 2 4 5\n21 5 8 2 4 5\n\n## Note the use of \"==\" for equality testing. This is a standard programming convention.\n\n\nSelect rows where B has its maximum value\n\n\nmydata[mydata$B == max(mydata$B), ]\n\n   A  B C D E\n27 8 11 5 9 8\n\n\n\nSelect even numbered rows only\n\n\nmydata[seq(2,26, by = 2), ]\n\n   A  B C D E\n2  2  5 1 1 2\n4  3  6 1 2 3\n6  3  6 1 2 4\n8  3  6 1 2 3\n10 4  7 1 2 4\n12 4  7 1 2 5\n14 4  7 1 3 4\n16 4  7 1 3 4\n18 5  8 2 3 5\n20 5  8 2 4 5\n22 6  9 3 5 6\n24 6  9 3 6 6\n26 7 10 4 8 7\n\n\n\nSelect columns A, C and E\n\n\nmydata[, c(1,3,5)] \n\n   A C E\n1  1 1 1\n2  2 1 2\n3  2 1 2\n4  3 1 3\n5  3 1 3\n6  3 1 4\n7  3 1 3\n8  3 1 3\n9  4 1 4\n10 4 1 4\n11 4 1 4\n12 4 1 5\n13 4 1 5\n14 4 1 4\n15 4 1 4\n16 4 1 4\n17 4 2 4\n18 5 2 5\n19 5 2 5\n20 5 2 5\n21 5 2 5\n22 6 3 6\n23 6 3 6\n24 6 3 6\n25 7 4 7\n26 7 4 7\n27 8 5 8\n\n## Or mydata[,c('A','C','E')] \n\n\nSort table by decreasing order of column B\n\n\nmydata[order(mydata$B, decreasing = TRUE), ]\n\n   A  B C D E\n27 8 11 5 9 8\n25 7 10 4 7 7\n26 7 10 4 8 7\n22 6  9 3 5 6\n23 6  9 3 5 6\n24 6  9 3 6 6\n18 5  8 2 3 5\n19 5  8 2 4 5\n20 5  8 2 4 5\n21 5  8 2 4 5\n9  4  7 1 2 4\n10 4  7 1 2 4\n11 4  7 1 2 4\n12 4  7 1 2 5\n13 4  7 1 2 5\n14 4  7 1 3 4\n15 4  7 1 3 4\n16 4  7 1 3 4\n17 4  7 2 3 4\n4  3  6 1 2 3\n5  3  6 1 2 3\n6  3  6 1 2 4\n7  3  6 1 2 3\n8  3  6 1 2 3\n2  2  5 1 1 2\n3  2  5 1 1 2\n1  1  4 1 1 1"
  },
  {
    "objectID": "02-IntroR.html#filtering-data",
    "href": "02-IntroR.html#filtering-data",
    "title": "Introduction to R",
    "section": "Filtering data",
    "text": "Filtering data\nSquare bracket notation can be handy for quickly filtering data frames or checking values, but can get cumbersome for more complex queries.\nThere is a subset() function in R specifically for filtering tables. This generally works better than using square brackets as it copes well with NA and NULL values.\n\nsubset(mydata, mydata$C == 3)\n\n   A B C D E\n22 6 9 3 5 6\n23 6 9 3 5 6\n24 6 9 3 6 6\n\n\nThe tidyverse packages have their own set of functions for filtering data and we will explore these in a later module."
  },
  {
    "objectID": "02-IntroR.html#plotting-with-r",
    "href": "02-IntroR.html#plotting-with-r",
    "title": "Introduction to R",
    "section": "Plotting with R",
    "text": "Plotting with R\nBase R has many built in functions for plotting data.\nWe recommend learning ggplot2 for more complex graphics but it is useful to know what base R offers. Remember, to get more information about the options available to a function, type ?function.\n\nHistograms\n\nhist(mydata$A)\n\n\n\n\n\n\n\n\nThe ChickWeight data set is another data frame built into R. It is a larger dataset, containing the weights of chicks on different diets, measured over time. Inspect the ChickWeight data using some of the functions you have used already.\n\n\n Challenge:\n\n\nWhat type of data is stored in the weight column?\nWhat is the mean weight of all the chicks?\nWhat type of data is stored in the Diet column?\nHow many rows are in this table (try the dim or nrow functions)?\n\n\n\n\n\nSolution. \n\n Solution:\n\n\nWhat type of data is stored in the weight column?\n\n\nclass(ChickWeight$weight)\n\n[1] \"numeric\"\n\n\n\nWhat is the mean weight of all the chicks?\n\n\nmean(ChickWeight$weight)\n\n[1] 121.8183\n\n\n\nWhat type of data is stored in the Diet column?\n\n\nclass(ChickWeight$Diet)\n\n[1] \"factor\"\n\n\n\nHow many rows are in this table (try the dim or nrow functions)?\n\n\nnrow(ChickWeight)\n\n[1] 578\n\n\n\n\n\n\n\nhist(ChickWeight$weight)\n\n\n\n\n\n\n\n\nWe can modify the number of vertical columns in a histogram with the argument breaks, to give us increased resolution.\n\nhist(ChickWeight$weight, breaks = 50)\n\n\n\n\n\n\n\n\n\n\nBoxplots\n\nboxplot(mydata)\n\n\n\n\n\n\n\n\n\nboxplot(mydata$A, mydata$B, names=c(\"Value A\", \"Value B\") , ylab=\"Count of Something\")\n\n\n\n\n\n\n\n\n\n\nScatter plots\n\nplot(x = mydata$A, y = mydata$B)\n\n\n\n\n\n\n\n\nTake a look at ?plot. You will see that the first argument is ‘x’ and the second is ‘y’. If you don’t name the arguments, the function will assume that the first argument is ‘x’ and the second is ‘y’.\n\n## This works because the first variable is assumed to be x and the second y\nplot(mydata$A, mydata$B)\n\nIf you name the arguments, you can put them in any order.\n\n## This works because the arguments are named\nplot(y = mydata$B, x = mydata$A)\n\nEarlier, we used the plot function with a single x argument: plot(cars). This worked because the x argument also accepts a data frame and will plot all combinations of columns. Try this for mydata and see what happens.\n\nplot(mydata)"
  },
  {
    "objectID": "02-IntroR.html#saving-images",
    "href": "02-IntroR.html#saving-images",
    "title": "Introduction to R",
    "section": "Saving images",
    "text": "Saving images\nThere are a few ways to save images in RStudio:\n\nUse the export button in the Plots pane in Rstudio.\n\nEasy to perform.\nDoesn’t work well for automated scripts.\nNo reproducible code to show how the image was generated.\n\n\n\nUse a graphics device function in your R code.\nUse the png function to save a png file (easy to load into web applications and presentations).\n\npng(\"filename.png\") \nboxplot(A, B, names=c(\"Value A\", \"Value B\") , ylab=\"Count of Something\")\ndev.off()\n\nThe dev.off() function closes the graphics device. In the code above, everything between png() and dev.off() is saved to ‘filename.png’.\nYou can also save as a pdf.\n\npdf(\"filename.pdf\") \nboxplot(A, B, names=c(\"Value A\", \"Value B\") , ylab=\"Count of Something\")\ndev.off()"
  },
  {
    "objectID": "02-IntroR.html#statistical-testing",
    "href": "02-IntroR.html#statistical-testing",
    "title": "Introduction to R",
    "section": "Statistical testing",
    "text": "Statistical testing\nR has many functions for statistical testing. We will cover a couple of examples here, but there are many more to explore. Remember, to get more information about the options available to a function, type ?function.\n\nT-test\nThe t.test function can be used to compare the numerical means of two groups. The t-test should only be used under the following assumptions.\n\nEach group is approximately normally distributed\nThe variance of the two groups is approximately equal\nThe two groups are independent of each other\n\nWe can use R to simulate a data frame of values for two groups, WT and KO, with 10 values in each group (this could be any sort of experimental measurement).\nBelow, we use the rnorm function to generate random numbers from a normal distribution. The mean and sd arguments specify the mean and standard deviation of the distribution.\n\nset.seed(123) # Set seed for reproducibility.\n\ndf &lt;- data.frame(\n  Sample = paste(\"Sample\", 1:20, sep=\"_\"),\n  Group = rep(c(\"WT\", \"KO\"), each=10),\n  Value = c(rnorm(10, mean=5, sd=1), rnorm(10, mean=6, sd=1))\n)\ndf\n\n      Sample Group    Value\n1   Sample_1    WT 4.439524\n2   Sample_2    WT 4.769823\n3   Sample_3    WT 6.558708\n4   Sample_4    WT 5.070508\n5   Sample_5    WT 5.129288\n6   Sample_6    WT 6.715065\n7   Sample_7    WT 5.460916\n8   Sample_8    WT 3.734939\n9   Sample_9    WT 4.313147\n10 Sample_10    WT 4.554338\n11 Sample_11    KO 7.224082\n12 Sample_12    KO 6.359814\n13 Sample_13    KO 6.400771\n14 Sample_14    KO 6.110683\n15 Sample_15    KO 5.444159\n16 Sample_16    KO 7.786913\n17 Sample_17    KO 6.497850\n18 Sample_18    KO 4.033383\n19 Sample_19    KO 6.701356\n20 Sample_20    KO 5.527209\n\n\n\n\n Discussion\n\nWhat is a normal distribution? How does rnorm work?\nWhat does set.seed do?\nWhat do the paste and rep functions do?\n\n\nWe can use the t.test function to compare the means of the two groups. The syntax for the t-test is t.test(Value ~ Group, data=df), where Value is the numeric variable we want to compare and Group is the categorical variable that defines the groups.\n\nt.test(Value ~ Group, data = df, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  Value by Group\nt = 2.5438, df = 18, p-value = 0.02036\nalternative hypothesis: true difference in means between group KO and group WT is not equal to 0\n95 percent confidence interval:\n 0.1974232 2.0705694\nsample estimates:\nmean in group KO mean in group WT \n        6.208622         5.074626 \n\n\n\n\n Discussion\n\nHow do we interpret the output of the t-test?\nAre the mean values of the WT and KO groups significantly different?\n\n\n\n\nFisher’s exact test\nThe fisher.test function can be used to test for association between two categorical variables.\n\nExample\nResearchers are testing a new anti-cancer drug in a mouse model. Tumour-bearing mice are randomly assigned to one of two treatment groups:\n\nControl (vehicle only)\nDrug-treated\n\nAfter 4 weeks of treatment, tumours are assessed for response. Each mouse is classified as:\n\nResponder (tumour size reduced ≥ 30%)\nNon-responder (tumour did not shrink sufficiently)\n\nBoth variables are categorical:\n\nTreatment: Control / Drug\nResponse: Responder / Non-responder\n\nLet’s create a contingency table of the two categorical variables, Treatment and Response, and use the fisher.test function to test for an association between them.\n\n# Create a contingency table\n\nct &lt;- matrix(\n  c(3, 17,   # Control: Responder, Non-responder\n    12, 8),  # Drug: Responder, Non-responder\n  nrow = 2,\n  byrow = TRUE\n)\n\nrownames(ct) &lt;- c(\"Control\", \"Drug\")\ncolnames(ct) &lt;- c(\"Responder\", \"Non_responder\")\n\nct\n\n        Responder Non_responder\nControl         3            17\nDrug           12             8\n\n\nNow we can perform the test on this contingency table.\n\nfisher.test(ct)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  ct\np-value = 0.007912\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.01758347 0.63708839\nsample estimates:\nodds ratio \n 0.1250459 \n\n\n\n\n Discussion\n\nIs there a significant association between treatment and response?"
  },
  {
    "objectID": "02-IntroR.html#case-study-quantitative-pcr",
    "href": "02-IntroR.html#case-study-quantitative-pcr",
    "title": "Introduction to R",
    "section": "Case Study: Quantitative PCR",
    "text": "Case Study: Quantitative PCR\nQuantitative PCR (qPCR) is a laboratory technique used to measure how much of a specific sequence is present in a sample. In gene expression experiments, RNA is first converted to complementary DNA (cDNA), and then qPCR is used to quantify how much of a particular gene is expressed.\nUnlike traditional PCR, qPCR measures amplification in real time using fluorescent dyes or probes. As DNA is amplified during each cycle, fluorescence increases. The instrument monitors this fluorescence and determines when it rises above a defined background threshold.\nThe key measurement in qPCR is the Ct value (Cycle threshold). The Ct is the number of PCR cycles required for fluorescence to cross a detection threshold. It is inversely related to the amount of starting material.\n\nInterpretation\n\nLow Ct → lots of starting material → high gene expression\nHigh Ct → little starting material → low gene expression\n\nFor example:\n\n\n\nSample\nCt value\nInterpretation\n\n\n\n\nSample A\n18\nHigh expression\n\n\nSample B\n25\nModerate expression\n\n\nSample C\n32\nLow expression\n\n\n\nEach PCR cycle approximately doubles the amount of DNA. That means:\n\nA difference of 1 Ct ≈ 2-fold difference in starting quantity\nA difference of 3 Ct ≈ ~8-fold difference\nA difference of 10 Ct ≈ ~1000-fold difference\n\n\n\nReference gene normalisation\nBiological samples vary in:\n\nTotal RNA amount\nRNA quality\nPipetting variation\n\nTo control for this, we measure a reference (housekeeping) gene that should not change between conditions.\nWe then calculate ΔCt by subtracting the Ct of the reference gene from the Ct of the target gene for each sample.\n\\[\nΔCt = Ct_{target} - Ct_{reference}\n\\]\n\n\nComparing conditions\nTo compare gene expression between conditions, we calculate the difference between the ΔCt of the treatment group and the ΔCt of the control group, which is called ΔΔCt:\n\\[\nΔΔCt = ΔCt_{treatment} - ΔCt_{control}\n\\]\nWe can then calculate the fold change in expression using the following formula:\n\\[\nFold~Change = 2^{-ΔΔCt}\n\\]\n\n\nStep 1: Load the data\nOur qPCR data consists of Ct values for a gene of interest and a reference gene, across 16 samples, split into two conditions (Control and Treatment). We will use this data to compare gene expression between the two conditions.\nYou can download the data from the URL below and save it in a new folder in your working directory.\n\n## Create a folder in the working directory\ndir.create(\"data\")\n\n## Download the qPCR file and save it in the data folder\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data.xlsx\", destfile = \"data/qpcr_data.xlsx\")\n\nOur data is in an Excel spreadsheet. We could open Excel and export the data as a tab delimited text file, then read it in using read.table or read.delim. However, R has a useful package called readxl for importing Excel files directly.\nTo access this package, we first need to install it:\n\ninstall.packages(\"readxl\")\n\nWe can now load the package and use the readxl functions in our current R session.\n\nlibrary(readxl)\n\n\n\n Challenge:\n\nUse a function in readxl to read in the qPCR data from the Excel file you downloaded. You can use the help documentation to find out how to do this.\n\nHow many rows and columns are in the data frame?\nWhat are the column names?\nHow many conditions are there and what are they called?\nHow many biological replicates do we have for each condition?\nWhat is the mean Ct value for the gene of interest in the control samples?\n\n\n\n\n\nSolution. \n\n Solution:\n\nRead in the qpcr data and inspect it using the functions we have already seen.\n\nqpcr &lt;- read_excel(\"data/qPCR_data.xlsx\")\nstr(qpcr)\n\ntibble [16 × 4] (S3: tbl_df/tbl/data.frame)\n $ Sample_ID: chr [1:16] \"S1\" \"S2\" \"S3\" \"S4\" ...\n $ Condition: chr [1:16] \"Control\" \"Control\" \"Control\" \"Control\" ...\n $ ct_gene  : num [1:16] 25.4 24.9 25.1 25.6 24.8 25.2 25 25.3 23.7 23.5 ...\n $ ct_ref   : num [1:16] 20.2 20.1 20.3 20 20.1 20.2 20 20.1 20.2 20 ...\n\nsummary(qpcr)\n\n  Sample_ID          Condition            ct_gene          ct_ref     \n Length:16          Length:16          Min.   :23.30   Min.   :20.00  \n Class :character   Class :character   1st Qu.:23.57   1st Qu.:20.07  \n Mode  :character   Mode  :character   Median :24.35   Median :20.10  \n                                       Mean   :24.38   Mean   :20.12  \n                                       3rd Qu.:25.12   3rd Qu.:20.20  \n                                       Max.   :25.60   Max.   :20.30  \n\n\n\nHow many rows and columns are in the data frame?\n\n\ndim(qpcr)\n\n[1] 16  4\n\n\n\nWhat are the column names?\n\n\ncolnames(qpcr)\n\n[1] \"Sample_ID\" \"Condition\" \"ct_gene\"   \"ct_ref\"   \n\n\n\nHow many conditions are there and what are they called?\n\n\n## The unique function gives the unique values in a vector\nunique(qpcr$Condition)\n\n[1] \"Control\"   \"Treatment\"\n\n\n\nHow many biological replicates do we have for each condition?\n\n\n## Show a table of the number of entries for each condition\ntable(qpcr$Condition)\n\n\n  Control Treatment \n        8         8 \n\n## Or convert Condition to a factor and use summary\nsummary(as.factor(qpcr$Condition))\n\n  Control Treatment \n        8         8 \n\n\n\nWhat is the mean Ct value for the gene of interest in the control samples?\n\n\nmean(qpcr$ct_gene[qpcr$Condition == \"Control\"])\n\n[1] 25.1625\n\n\n\n\n\n\n\n\nStep 2: Calculate ΔCt\nTo calculate ΔCt, we need to subtract the Ct value of the reference gene from the Ct value of the gene of interest for each sample.\nWe can create new columns in a data frame using the $ symbol.\n\n## This operation is performed on each row of the data frame, so we get a new column with the ΔCt values for each sample.\nqpcr$delta_ct &lt;- qpcr$ct_gene - qpcr$ct_ref\n\nqpcr\n\n# A tibble: 16 × 5\n   Sample_ID Condition ct_gene ct_ref delta_ct\n   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 S1        Control      25.4   20.2      5.2\n 2 S2        Control      24.9   20.1      4.8\n 3 S3        Control      25.1   20.3      4.8\n 4 S4        Control      25.6   20        5.6\n 5 S5        Control      24.8   20.1      4.7\n 6 S6        Control      25.2   20.2      5  \n 7 S7        Control      25     20        5  \n 8 S8        Control      25.3   20.1      5.2\n 9 S9        Treatment    23.7   20.2      3.5\n10 S10       Treatment    23.5   20        3.5\n11 S11       Treatment    23.8   20.1      3.7\n12 S12       Treatment    23.4   20.2      3.2\n13 S13       Treatment    23.6   20.1      3.5\n14 S14       Treatment    23.9   20        3.9\n15 S15       Treatment    23.3   20.2      3.1\n16 S16       Treatment    23.5   20.1      3.4\n\n\nA new column delta_ct has been added to the data frame, which contains the ΔCt values for each sample.\n\n\nStep 3: Visualise the data\nWe can use a boxplot to visualise the ΔCt values in the control and treatment samples.\n\nboxplot(delta_ct ~ Condition, data = qpcr,\n        ylab = \"Delta Ct\",\n        main = \"Gene expression by condition\")\n\n\n\n\n\n\n\n\nWe can clearly see a difference between the two conditions, but is this difference statistically significant? We can use a t-test to find out.\n\n\nStep 4: Perform a t-test\nA t-test is a statistical test used to compare the means of two groups. In our case, we want to compare the mean ΔCt values between the control and treatment groups.\nThe t-test is a valid test to use if the data in each group meets the following assumptions.\n\nThe data in each group is approximately normally distributed\nThe variance of the two groups is approximately equal\nThe two groups are independent of each other\n\nLater on, we will see how to check these assumptions and use alternative tests if they are not met. For now, we can assume that the data meets these assumptions:\n\nBox plots show approximately normal distribution\nVariance looks approximately equal\nThe two groups are independent (different samples in each group)\n\n\n\n Challenge:\n\nUse a t-test to decide if the mean values of Control and Treatment differ significantly.\n\nDoes the treatment have a significant effect on gene expression?\nDoes the treatment increase or decrease gene expression?\n\n\n\n\n\nSolution. \n\n Solution:\n\nUse a t-test to decide if the mean values of Control and Treatment differ more than would be expected by chance.\n\nt.test(delta_ct ~ Condition, data = qpcr, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  delta_ct by Condition\nt = 11.391, df = 14, p-value = 1.821e-08\nalternative hypothesis: true difference in means between group Control and group Treatment is not equal to 0\n95 percent confidence interval:\n 1.268289 1.856711\nsample estimates:\n  mean in group Control mean in group Treatment \n                 5.0375                  3.4750 \n\n\n\nDoes the treatment have a significant effect on gene expression?\n\nThe p-value is less than 0.05, so we can reject the null hypothesis and conclude that there is a significant difference in gene expression between the control and treatment groups.\nYou can save the result of the t-test as an object and print the p-value:\n\nresult &lt;- t.test(delta_ct ~ Condition, data = qpcr, var.equal=TRUE)\nresult$p.value\n\n[1] 1.820703e-08\n\n\n\nDoes the treatment increase or decrease gene expression?\n\nThe mean ΔCt value for the treatment group is lower than the control group, which indicates that the treatment increases gene expression (remember that a lower ΔCt means higher expression).\n\n\n\n\n\n\nStep 5: Calculate fold change\nWe now know that there is a significant difference in gene expression between the control and treatment groups, but how much of a difference is there? We can calculate the fold change in gene expression using the formula:\n\\[\nFold~Change = 2^{-ΔΔCt}\n\\]\nTo calculate ΔΔCt, we need to subtract the mean ΔCt of the control group from the mean ΔCt of the treatment group.\n\nmean_control &lt;- mean(qpcr$delta_ct[qpcr$Condition == \"Control\"])\n\nmean_treatment &lt;- mean(qpcr$delta_ct[qpcr$Condition == \"Treatment\"])\n\ndelta_delta_ct &lt;- mean_treatment - mean_control\n\nNow we can calculate the fold change:\n\nfold_change &lt;- 2^(-delta_delta_ct)\nfold_change\n\n[1] 2.953652\n\n\nExpression is almost 3 times higher in the treatment group compared to the control group. When reporting this analysis, you should show the p-value and the fold change, as well as a visualisation of the data. The p-value tells us if the difference is statistically significant, while the fold change tells us how big the difference is (effect size).\nWe will revisit this case study in later modules to see how to do the same analysis using dedicated statistical and visualisation packages for high quality presentation."
  },
  {
    "objectID": "02-IntroR.html#summary",
    "href": "02-IntroR.html#summary",
    "title": "Introduction to R",
    "section": "Summary",
    "text": "Summary\nCongratulations! You have completed your first lesson in R. Hopefully you have a better understanding of what R is, its syntax and data types, and how to use it to import and analyse data.\nNext we will start to look at the strengths of R as a programming language and how to use it to write scripts that can be easily reproduced and shared with others.\n\n\n Resources\n\n\nR manual: https://cran.r-project.org/doc/manuals/r-patched/R-intro.html\nRStudio user guide: https://docs.posit.co/ide/user/\nRStudio cheat-sheet: https://rstudio.github.io/cheatsheets/html/rstudio-ide.html\n\n\n\n\n\n Key points\n\n\nR is a functional programming language for data science\nRStudio is an interactive environment for programming in R\nR has different data types and structures for organising data\nR code is run within functions, which have different arguments for customisation\nR functions can be used to import, manipulate and plot data\nThere are many functions for statistical analysis in R"
  },
  {
    "objectID": "02-Setup.html",
    "href": "02-Setup.html",
    "title": "Setup",
    "section": "",
    "text": "Project Setup\n\nCreate a new project in RStudio called Introduction to R.\nInstall the following packages:\n\n\ninstall.packages(\"read_excel\")\n\n\n\nData\nYou will need to download data throughout this session using the download.file() function in R.\nIf you are using a Windows computer you will need to explicitly add the argument mode = \"wb\".\n\n## Create a directory to store the data\ndir.create(\"data\")\n\n## Mac or Linux\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data2.xlsx\", destfile = \"data/qpcr_data2.xlsx\")\n\n## Windows\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data2.xlsx\", destfile = \"data/qpcr_data2.xlsx\", mode = \"wb\")"
  },
  {
    "objectID": "03-tidyverse.html",
    "href": "03-tidyverse.html",
    "title": "The Tidyverse",
    "section": "",
    "text": "Understand the philosophy of Tidy Data\nGet to know some of the Tidyverse packages\nThe tidyverse is a suite of packages that includes libraries such as dplyr and ggplot2. These packages are designed for data science and share underlying principles, grammar and data structures. There are many ways to do the same thing in R, but following the philosophy of tidy data and using the tidyverse packages will keep your data organised and make analysis easier in the long run."
  },
  {
    "objectID": "03-tidyverse.html#tidy-data",
    "href": "03-tidyverse.html#tidy-data",
    "title": "The Tidyverse",
    "section": "Tidy data",
    "text": "Tidy data\nData can be represented in many different ways across multiple tables but the tidyverse packages are specifically designed to work with tidy datasets. Tidy data conforms to the following criteria:\n\nEach variable has its own column\nEach row is a single observation\nEach value has its own cell\n\n\nThis is the optimal structure when working in R and provides consistency amongst your datasets. Getting your data into R and wrangling it into the correct format is always the first step in your analysis. Fortunately, the tidyr package contains many functions to tidy up your dataset.\nWe will start by reading in a dataset. The readr package has functions for importing data as tibbles. Tibbles are the tidyverse compatible version of an R data frame. They have stricter formatting and allow you to perform grouping of variables as we will see in the next section.\n\nlibrary(tidyverse)\n\n## If you already have the data installed on your computer you can read from a file:\nsurveys &lt;- read_csv(\"data/surveys_complete.csv\")\n\n\n## Otherwise you can read from a URL\nsurveys &lt;- read_csv(\"http://bifx-core3.bio.ed.ac.uk/training/R_dplyr_and_ggplot2/data/surveys_complete.csv\")\n\n\n\n Discussion\n\n\nLook at the options available in the read_csv function and compare this with the read.table function we saw earlier.\nWhat other readr functions can you find?\n\n\n\nThis dataset contains observations from a field survey of different organisms at different sites (plots). Let’s inspect the data.\n\n## Type an R objects name to print the contents\nsurveys\n\n# A tibble: 30,463 × 13\n   record_id month   day  year plot_id species_id sex   hindfoot_length weight\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1       845     5     6  1978       2 NL         M                  32    204\n 2      1164     8     5  1978       2 NL         M                  34    199\n 3      1261     9     4  1978       2 NL         M                  32    197\n 4      1756     4    29  1979       2 NL         M                  33    166\n 5      1818     5    30  1979       2 NL         M                  32    184\n 6      1882     7     4  1979       2 NL         M                  32    206\n 7      2133    10    25  1979       2 NL         F                  33    274\n 8      2184    11    17  1979       2 NL         F                  30    186\n 9      2406     1    16  1980       2 NL         F                  33    184\n10      3000     5    18  1980       2 NL         F                  31     87\n# ℹ 30,453 more rows\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\n\n\n## Use the View function to see the full table\nView(surveys)\n\n\n## We can look at the structure of the dataset\nstr(surveys)\n\nspc_tbl_ [30,463 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:30463] 845 1164 1261 1756 1818 ...\n $ month          : num [1:30463] 5 8 9 4 5 7 10 11 1 5 ...\n $ day            : num [1:30463] 6 5 4 29 30 4 25 17 16 18 ...\n $ year           : num [1:30463] 1978 1978 1978 1979 1979 ...\n $ plot_id        : num [1:30463] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:30463] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : chr [1:30463] \"M\" \"M\" \"M\" \"M\" ...\n $ hindfoot_length: num [1:30463] 32 34 32 33 32 32 33 30 33 31 ...\n $ weight         : num [1:30463] 204 199 197 166 184 206 274 186 184 87 ...\n $ genus          : chr [1:30463] \"Neotoma\" \"Neotoma\" \"Neotoma\" \"Neotoma\" ...\n $ species        : chr [1:30463] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : chr [1:30463] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n $ plot_type      : chr [1:30463] \"Control\" \"Control\" \"Control\" \"Control\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n Further Resources\n\n\nThere are cheatsheets available for many tidyverse and rstudio packages that will help you to choose the correct functions.\nTake a look at these slides or www.tidyverse.org for more information on the tidyverse.\n\n\n\n\n\n Key points\n\n\nThe tidyverse is a suite of R packages\nStick to the principles and philosophy of tidy data\nUse the readr package to import data as tibbles\nUse further tidyverse packages to tidy, re-format and visualise data"
  },
  {
    "objectID": "03-ggplot2.html",
    "href": "03-ggplot2.html",
    "title": "ggplot2",
    "section": "",
    "text": "Build graphics layer by layer with ggplot2\nCreate different types of graphics by applying geometries\nApply additional layers to a graphic\nVisually subset graphics by applying fills and gradients\nChange the appearance of graphics using themes\nCreate sub-graphics by applying facets\nCreate and save basic graphics\nUse additional libraries such as plotly to enhance the utility of graphics.\nggplot2 is a plotting package that makes it simple to create complex graphics from data frames. It provides a grammar for specifying which variables to plot, how they are displayed, and general visual properties.\nFirst, make sure you load all of the required libraries and datasets. There are quite a few new libraries here and we will explain them as we go.\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(plotly)\nlibrary(ggrepel)\nlibrary(ggpubr)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(ggsci)\nlibrary(patchwork)\nlibrary(gghighlight)\n\n#This dataset is built in to R\ndata(iris)\n\n#Import from url\nsurveys &lt;- read_csv(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/surveys_complete.csv\")"
  },
  {
    "objectID": "03-ggplot2.html#fishers-iris-dataset-pre-installed-in-r",
    "href": "03-ggplot2.html#fishers-iris-dataset-pre-installed-in-r",
    "title": "ggplot2",
    "section": "Fisher’s Iris dataset (pre-installed in R)",
    "text": "Fisher’s Iris dataset (pre-installed in R)\n\nFisher examined the length and width of petals and sepals in irises to determine a species classification algorithm. Here we will explore the relationship between species and the dimensions of the flowers via the ggplot2 plotting package. Fisher’s data is stored as a built in data set in R. To see the data type:\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nThis data frame has two types of data, continuous and discrete.\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nThe continuous data is of type number and the discrete data is of type factor, which can be one of the 3 species:\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nThe summary() function gives a summary of data in a column. For factors it will give us the count for each categorical variable.\n\nsummary(iris$Species)\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\nWe can also use run summary() on an entire dataframe or tibble. Take a look at the different column types.\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50"
  },
  {
    "objectID": "03-ggplot2.html#building-a-ggplot",
    "href": "03-ggplot2.html#building-a-ggplot",
    "title": "ggplot2",
    "section": "Building a ggplot",
    "text": "Building a ggplot\nggplot graphics are built step by step by adding new elements. This layered approach allows for extensive flexibility and customisation of plots. To build a ggplot, we use the following basic template:\n\nggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;()\n\nLet’s explore the iris dataset with ggplot. Use the ggplot() function and bind the plot to a specific data frame using the data argument.\n\nggplot(data = iris)\n\n\n\n\n\n\n\n\nOur plot is completely empty! This is because we haven’t specified what to plot yet.\nNext, we define a mapping. The mapping argument tells ggplot which variables in the data frame to map to visual aesthetics of the plot. We use the aes() function to do this.\nThe mapping is defined by selecting an aesthetic (e.g. x/y positions or characteristics such as size, shape, color, etc.) and assigning a variable from the data frame to it.\nFor example, to map the Sepal.Length variable to the x-axis and Sepal.Width to the y-axis we would use:\n\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width))\n\n\n\n\n\n\n\n\nNow we have axes and a grid, but still no data! We still need to tell ggplot how to represent the data on the plot. This is done by adding a geometry to the plot.\nGeometries are graphical representations of the data (points, lines, bars etc). The ggplot2 package offers many different geom_*() functions, here are a few commonly used examples:\n\ngeom_point() for scatter plots, dot plots, etc.\ngeom_histogram() for histograms\ngeom_bar() or geom_col() for bar plots\ngeom_boxplot() for, well, boxplots!\ngeom_line() for trend lines, time series, etc."
  },
  {
    "objectID": "03-ggplot2.html#scatterplots",
    "href": "03-ggplot2.html#scatterplots",
    "title": "ggplot2",
    "section": "Scatterplots",
    "text": "Scatterplots\nTo add a geom to the plot use the + operator. Let’s use geom_point() to plot two continuous variables first. The data and mapping are always the first two arguments to ggplot so we can leave these out if arguments are provided in this order:\n\nggplot(iris,aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThe + in the ggplot2 package is particularly useful because it allows us to modify existing ggplot objects. This means we can easily set up plot templates and conveniently explore different types of plots, so the above plot can also be generated with code like this:\n\n# Assign plot to a variable\np &lt;- ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width))\n\n# Draw a scatter plot\np + geom_point()\n\n\n\n\n\n\n\n\nThe geom_point() function has many options to customise the plot, for example we can change the colour of the points:\n\np + geom_point(colour = \"red\")\n\n\n\n\n\n\n\n\nThis isn’t very informative though. It would be better if we could make the points different colours depending on which species they belong to. We can do this by mapping the colour aesthetic to the Species variable in our data frame.\n\np &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colour = Species))\np + geom_point()\n\n\n\n\n\n\n\n\nAnything you put in the ggplot() function is inherited by subsequent layers. If you want to specify mappings for a given geom independently, you can add these within a geom instead.\n\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) + \n  geom_point(aes(colour = Species))\n\n\n\n\n\n\n\n\nThis is really useful when we want to plot multiple geoms on the same graph with different aesthetics. Let’s add a second layer of points with a different shape and size to the plot.\n\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) + \n  geom_point(aes(colour = Species)) +\n  geom_point(shape=2, size = 8)\n\n\n\n\n\n\n\n\nOnly the first layer is coloured by species. If we move the colour aesthetic to the ggplot function, both layers will be coloured by species:\n\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colour=Species)) + \n  geom_point() +\n  geom_point(shape=2, size = 8)\n\n\n\n\n\n\n\n\nIn the aes() function, colour is used assign colours for lines and points. If you want to colour shapes such as bars in barplots and histograms you need to use fill.\nEach function within the ggplot package has its own help file associated with it.\n\n?geom_point()\n\nNote that all the geometries also define a statistical transformation. In the help file of geom_point you’ll see stat = \"identity\". This means that geom_point() plots the raw values by default. Other geometries have different defaults, for instance geom_histogram() bins values together."
  },
  {
    "objectID": "03-ggplot2.html#histograms",
    "href": "03-ggplot2.html#histograms",
    "title": "ggplot2",
    "section": "Histograms",
    "text": "Histograms\nHere is an example of the histogram geometry:\n\n#Visualise the distribution of Sepal.Width with a histogram\nh &lt;- ggplot(iris, aes(Sepal.Width, fill = Species )) +  \n  geom_histogram(binwidth = 0.1)\n\nh\n\n\n\n\n\n\n\n\n\n\n Discussion\n\nTry altering the binwidth parameter to see how this affects the plot.\n\n\n\n\n Challenge:\n\nUse what you have learned to create a scatterplot of Sepal.Width per Species.\n\n\n\n\nSolution. \n\n Solution:\n\n\nggplot(iris, aes(x=Species, y=Sepal.Width )) + geom_point() \n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above, we can see a distribution of Sepal.Width values for each species. The histogram is good for showing the distribution, but the overlap makes it difficult to compare between species.\nThe scatterplot separates our species better, but it’s difficult to visualise the distribution and impossible to tell how many data points overlap. Boxplots and violin plots are good alternatives for visualising distributions of data within groups."
  },
  {
    "objectID": "03-ggplot2.html#boxplots",
    "href": "03-ggplot2.html#boxplots",
    "title": "ggplot2",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots are an effective way to visualise distributions of data within groups.\n!!! INFO BOX!!!\nThe boxplot geometry requires the x aesthetic to be a categorical variable and the y aesthetic to be numerical.\n\nb &lt;- ggplot(iris, aes(x=Species, y=Sepal.Width )) +  geom_boxplot() \nb\n\n\n\n\n\n\n\n\nTo flip the axes we can use another function called coord_flip().\n\nb + coord_flip()\n\n\n\n\n\n\n\n\nIt would be more visually appealing to have the species ordered by the median sepal width, so that our plot is ordered from smallest to largest.\nWe can reorder aesthetics in ggplot by using the fct_reorder() function from the forcats package. This function takes a factor (categorical variable) and a numeric variable and reorders the factor levels based on the values of the numeric variable.\nThe forcats package is also a part of the tidyverse and has a lot of functions for ordering, labeling and manipulating factors.\n\nb &lt;- ggplot(iris, aes(x = fct_reorder(Species,Sepal.Width), y=Sepal.Width )) + \n  geom_boxplot()\n\nb\n\n\n\n\n\n\n\n\nWe probably want to relabel the x-axis now:\n\nb &lt;- b + xlab(\"Species\")\nb"
  },
  {
    "objectID": "03-ggplot2.html#adding-layers",
    "href": "03-ggplot2.html#adding-layers",
    "title": "ggplot2",
    "section": "Adding layers",
    "text": "Adding layers\nAdding points to a boxplot gives a better representation of the number of measurements and their distribution.\n\nb + geom_point(colour = \"forest green\")\n\n\n\n\n\n\n\n\nThis is okay, but we know there are some dots where values overlap and it’s difficult to see how many data points we really have. We can use the alpha option within our geometry to increase transparency.\n\nb + geom_point(colour=\"forest green\",alpha=0.3)\n\n\n\n\n\n\n\n\nThis is slightly better, we can see that darker points have more overlap, but it isn’t great. The geom_jitter() function is a good alternative to geom_point() in this example as it randomly shifts data points to avoid overlap. We can colour by Species so there is no confusion between plots.\n\nb + geom_jitter(aes(colour = Species))"
  },
  {
    "objectID": "03-ggplot2.html#violin-plots",
    "href": "03-ggplot2.html#violin-plots",
    "title": "ggplot2",
    "section": "Violin plots",
    "text": "Violin plots\n\n\n Challenge:\n\nBoxplots are useful summaries but can hide the shape of non-normal distributions. For example, if the distribution is bimodal, we would not see it in a boxplot. An alternative to the boxplot is the violin plot, where the shape of the density of points is drawn.\nReplace the box plot with a violin plot; see geom_violin().\n\n\n\n\nSolution. \n\n Solution:\n\n\nggplot(iris, aes(x = fct_reorder(Species, Sepal.Width), y = Sepal.Width, fill = Species )) + \n  geom_violin() +\n  xlab(\"Species\") \n\n\n\n\n\n\n\n\n\n\nCan you add a boxplot and datapoints over the violin plot?\n\n\n\n\nSolution. \n\n Solution:\n\n\nggplot(iris, aes(x = fct_reorder(Species, Sepal.Width), y = Sepal.Width)) + \n  geom_violin(aes(fill = Species),alpha=0.3)+ \n  geom_boxplot()+\n  geom_jitter(aes(colour = Species))+\n  xlab(\"Species\")"
  },
  {
    "objectID": "03-ggplot2.html#themes",
    "href": "03-ggplot2.html#themes",
    "title": "ggplot2",
    "section": "Themes",
    "text": "Themes\nLet’s return to our scatter plot and play around with plotting themes. Themes are a set of pre-defined settings that control the overall appearance of a plot, including background color, grid lines, font size, and more. Pre-set themes allow you to quickly change the look of your plot without having to manually adjust each individual element.\n\np &lt;- ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) +  geom_point()\n\nWe can continue to modify this scatter plot. Let’s make the axis a bit prettier with the xlab() and ylab() functions:\n\np &lt;- p + xlab(\"Sepal length\") + ylab(\"Sepal width\") \np\n\n\n\n\n\n\n\n\nAll the characteristics of the plot, such as text size and the background are managed by the function called theme(). To see what a theme can change:\n\n?theme\n\nYou can use a theme with predefined defaults e.g:\n\np + theme_dark() #Dark theme\n\n\n\n\n\n\n\n#OR\np + theme_bw() #Black and white theme\n\n\n\n\n\n\n\n\nYou can also try theme_light, theme_minimal, theme_void, or create you own from scratch:\n\np + theme(\n            panel.background = element_blank(), \n            panel.grid.major = element_line(colour = \"darkgrey\"), \n            text = element_text(size=20), \n            axis.title.x=element_blank(), \n            axis.title.y=element_blank()\n            )\n\n\n\n\n\n\n\n# Note you can save your theme and reuse it \ntheme_for_nature &lt;- theme(\n            panel.background = element_blank(), \n            panel.grid.major = element_line(colour = \"darkgrey\"), \n            text = element_text(size=20), \n            axis.title.x=element_blank(), \n            axis.title.y=element_blank() \n            )\n\nWe can then reuse a theme, for example on the histogram we made earlier.\n\nh + theme_for_nature\n\n\n\n\n\n\n\n\nThe ggplot package has a lot of built in themes. Try typing “theme_” and give some of them a try. The ggthemes and ggpubr packages also contain a selection of prebuilt themes e.g:\n\nlibrary(ggthemes)\np + theme_fivethirtyeight()\n\n\n\n\n\n\n\n\nWe can set a default theme to use in all ggplots:\n\ntheme_set(theme_bw())\n\nWe can also use a base theme and customise specific settings.\n\ntheme_set(theme_bw(base_size = 12))"
  },
  {
    "objectID": "03-ggplot2.html#adding-colours-to-plots",
    "href": "03-ggplot2.html#adding-colours-to-plots",
    "title": "ggplot2",
    "section": "Adding colours to plots",
    "text": "Adding colours to plots\nAs we have seen, points, lines and shapes can be coloured by a value in your data frame using the aes() function. Earlier we coloured by a factor but we can also colour by a continuous value which will create a gradient of colour. Lets look at the Petals this time and colour by the ratio of Sepal.Length to Sepal.Width:\nFirst, create a new version of the iris dataset with a new column called Sepal.Ratio:\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Ratio\n1          5.1         3.5          1.4         0.2  setosa    1.457143\n2          4.9         3.0          1.4         0.2  setosa    1.633333\n3          4.7         3.2          1.3         0.2  setosa    1.468750\n4          4.6         3.1          1.5         0.2  setosa    1.483871\n5          5.0         3.6          1.4         0.2  setosa    1.388889\n6          5.4         3.9          1.7         0.4  setosa    1.384615\n\n\nNow create a scatter plot of Petal.Length vs Petal.Width and colour by Sepal.Ratio:\n\nq &lt;- ggplot(iris2, aes(x = Petal.Length, y = Petal.Width, colour = Sepal.Ratio)) +\n  geom_point(alpha=0.5)\nq\n\n\n\n\n\n\n\n\nBecause the colour is mapped to a continuous variable, ggplot has automatically created a gradient of colour.\nTo change the default colours, we use the scale_color_* functions of which there are many. Some are built into ggplot2 and others exist in external packages such as viridis or ggthemes. The viridis and ColorBrewer palettes are particularly useful and worth investigating. The ggsci package contains palettes based on key scientific journals.\n!!!!! Viridis colour blind, data visualisation tricks and tips\n\nContinuous scales\nTry the different scale options in the code below:\n\nlibrary(viridis)\nlibrary(RColorBrewer)\n\n#default\nq + scale_colour_continuous()\n\n\n\n\n\n\n\n#ColorBrewer palletes (many to choose from)\nq + scale_colour_distiller(palette = \"Spectral\")\n\n\n\n\n\n\n\n#Viridis colour scales (many to choose from)\nq + scale_colour_viridis()\n\n\n\n\n\n\n\n\nAn alternative method is to use the scale_colour_gradient* functions to define your own gradient e.g:\n\nq + scale_color_gradient2(high = \"darkred\", low = \"white\",  mid = \"red\", midpoint=2)\n\n\n\n\n\n\n\n\n\n\nDiscrete scales\nThere are also colour scales for discrete variables. Note that we must use fill for colouring boxes.\n\nbp &lt;- ggplot(iris2, aes(Species, Sepal.Length, fill = Species)) +\n  geom_boxplot()\n\n#Default\nbp + scale_fill_discrete()\n\n\n\n\n\n\n\n#Viridis\nbp + scale_fill_viridis(discrete = TRUE)\n\n\n\n\n\n\n\n#ColorBrewer Palettes\nbp + scale_fill_brewer(palette = \"Dark2\")\n\n\n\n\n\n\n\n#GGSci - Nature publishing group\nlibrary(ggsci)\nbp + scale_fill_npg()\n\n\n\n\n\n\n\n\nAlternatively you can manually choose your own colours with scale_fill_manual():\n\nh + scale_fill_manual(values = c(\"forest green\", \"dodger blue\", \"firebrick\"))\n\n\n\n\n\n\n\n\nYou can also use hex codes for colours:\n\nh + scale_fill_manual(values = c(\"#DDDD33\",\"#EE3344\", \"#1133FF\"))\n\n\n\n\n\n\n\n\n\n\n Further Learning\n\nThe options for colouring graphs are huge.\n\nColor brewer 2 is a great site for getting the hex values of colours to suit needs such as printer or colour blind friendliness.\nCoolors and Colormind are colour palette generators."
  },
  {
    "objectID": "03-ggplot2.html#adding-more-variables",
    "href": "03-ggplot2.html#adding-more-variables",
    "title": "ggplot2",
    "section": "Adding more variables",
    "text": "Adding more variables\nTake a look at this example:\n\nggplot(iris2, aes(x=Petal.Length, y=Petal.Width, colour=Sepal.Ratio)) +\n  geom_point()\n\n\n\n Challenge:\n\nSee if you can represent some of the other variables from the iris dataset in this plot as well. Hint: There are several other aesthetic mappings such as size and shape.\n\n\n\n\nSolution. \n\n Solution:\n\n\nggplot(iris2, aes(x = Petal.Length, y = Petal.Width, colour = Sepal.Ratio, shape = Species, size = Sepal.Length)) +\n  geom_point(alpha=0.5) +\n  theme_bw()"
  },
  {
    "objectID": "03-ggplot2.html#faceting",
    "href": "03-ggplot2.html#faceting",
    "title": "ggplot2",
    "section": "Faceting",
    "text": "Faceting\nWhen we have defined groups within our data, we can split our data into separate plots by using facets.\nLet’s look at plot q again.\n\nq\n\n\n\n\n\n\n\n\nLet’s split this plot by species. This is achieved using either the facet_grid() or facet_wrap() functions:\n\nq + facet_wrap(~Species, nrow = 1, scales = \"fixed\")\n\n\n\n\n\n\n\n\nTry playing around with the nrow and scales parameters in facet_wrap().\nNote that the facet variable is preceded by the ~ character. This is used to define formulas in R and is a common way to specify the variable to facet by.\nThe facet_wrap() function is useful when you are splitting by one factor, whereas the facet_grid() function is useful when you are splitting by multiple factors. Let’s add another categorical variable to iris2. We can randomly assign a country, one of four nations of origin, to each observation:\n\ncountries &lt;- c(\"Italy\", \"Spain\", \"France\", \"UK\")\n\n#Sample will randomly select a value for each row\niris2 &lt;- iris2 |&gt; mutate(Country = sample(countries, nrow(iris2), replace = TRUE))\n\niris2 |&gt; head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Ratio Country\n1          5.1         3.5          1.4         0.2  setosa    1.457143  France\n2          4.9         3.0          1.4         0.2  setosa    1.633333   Italy\n3          4.7         3.2          1.3         0.2  setosa    1.468750   Italy\n4          4.6         3.1          1.5         0.2  setosa    1.483871  France\n5          5.0         3.6          1.4         0.2  setosa    1.388889   Italy\n6          5.4         3.9          1.7         0.4  setosa    1.384615   Spain\n\n\nNow we can facet by both country and species:\n\nq2 &lt;- ggplot(iris2, aes(x = Petal.Length, y = Petal.Width, colour = Sepal.Ratio)) +\n  geom_point()\nq2 + facet_grid(Country ~ Species)\n\n\n\n\n\n\n\n\n\n\n Challenge:\n\nUse dplyr and ggplot to display the mean petal length for each species in each country except for those found in France. Use colouring and faceting to enhance the plot.\n\n\n\n\nSolution. \n\n Solution:\n\n\niris2 |&gt;\nfilter(Country != \"France\") |&gt; \ngroup_by(Species, Country) |&gt;\nsummarise(Mean = mean(Petal.Length)) |&gt; \nggplot(aes(x = Country, y = Mean, colour = Species)) + \n  geom_point(size = 4) + \n  facet_wrap(~Species) + \n  labs(title=\"Mean Petal Length\")"
  },
  {
    "objectID": "03-ggplot2.html#adding-labels",
    "href": "03-ggplot2.html#adding-labels",
    "title": "ggplot2",
    "section": "Adding labels",
    "text": "Adding labels\nYou can add labels to points in your graphs. One of the best ways to do this is to use the package ggrepel.\n\nlibrary(ggrepel)\n# you can use geom_text_repel() or geom_label_repel() to label whatever you want with non-overlapping labels. In the brackets use conditional subsetting to only label the interesting elements of your data.\n\nggplot(iris2, aes(Petal.Width, Petal.Length, colour = Sepal.Ratio)) +\n  geom_point() +\n  geom_label_repel(aes(label = ifelse(Petal.Length &gt; 6.4 ,as.character(Species),'')))\n\n\n\n\n\n\n\n\n\nHighlight points or lines\nYou can choose to highlight specific points or lines using gghighlight:\n\nlibrary(gghighlight)\nggplot(iris2,aes(Petal.Width, Petal.Length, colour = Sepal.Ratio)) +\n  geom_point() +\n  gghighlight(Petal.Length &gt; 6.4,label_key = Species)"
  },
  {
    "objectID": "03-ggplot2.html#saving-plots",
    "href": "03-ggplot2.html#saving-plots",
    "title": "ggplot2",
    "section": "Saving plots",
    "text": "Saving plots\nIn RStudio there are many options to save the image. However, if you are are wanting to use ggplot2 in a script, or via web interfaces, you can export a graph using the function ggsave().\n\n#save a png file \nggsave(\"IrisScatterplot.png\", p)\n#save a pdf file\nggsave(\"IrisScatterplot.pdf\", p)\n\nThe image format is automatically assigned from the file extension you use in the filename. Within ggsave() you can also set the resolution for the image as well as the height and width of the image. See the help page for ggsave() for more options."
  },
  {
    "objectID": "03-ggplot2.html#arranging-multiple-plots",
    "href": "03-ggplot2.html#arranging-multiple-plots",
    "title": "ggplot2",
    "section": "Arranging multiple plots",
    "text": "Arranging multiple plots\nPlacing ggplots side by side can be performed with packages like gridExtra and patchwork. Patchwork uses simple formulas to arrange ggplots:\n\nlibrary(patchwork)\n\n## On top\nq / bp\n\n\n\n\n\n\n\n\n\n## Side by side\nq + bp\n\n\n\n\n\n\n\n\n\n## 2 plots on top, 1 on bottom\n(q + h) / bp\n\n\n\n\n\n\n\n\n\n## Collect the guides together on one side\n(q + h) / bp + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nUse ggsave to save the image:\n\nggsave(\"DoublePlot.png\",q / bp)"
  },
  {
    "objectID": "03-ggplot2.html#additional-functions-to-try",
    "href": "03-ggplot2.html#additional-functions-to-try",
    "title": "ggplot2",
    "section": "Additional functions to try",
    "text": "Additional functions to try\n\nCut functions\nThe cut_* functions in ggplot2 can turn continous data into discrete levels. In this example we create a new column that puts the data into 5 groups of equal size based on Sepal.Length:\n\niris2 &lt;- iris2 |&gt; mutate(Sepal.Length.Group=cut_number(Sepal.Length,5))\n\nggplot(iris2,aes(Sepal.Length,Sepal.Width,fill = Sepal.Length.Group)) +  \n  geom_violin() +\n  labs(fill=\"Sepal length intervals\", x=\"Sepal length\",y=\"Sepal width\")\n\n\n\n\n\n\n\n\nNote the use of the labs() function to change multiple labels at once.\nHave a look at the difference between the cut_number, cut_interval and cut_width functions.\n\n\nScaling data\nLet’s look at a larger dataset like the surveys_complete data we used earlier:\n\nggplot(surveys,aes(weight,hindfoot_length))+geom_point()\n\n\n\n\n\n\n\n\nFor axes with large values or very dispersed values it can be useful to rescale using a log axis. This can be done in two ways:\n\n#We can transform the values in our ggplot call:\nggplot(surveys,aes(log10(weight),hindfoot_length)) + geom_point()\n\n\n\n\n\n\n\n\n\n#OR we can change the axis to a log scale\nggplot(surveys,aes(weight,hindfoot_length))+geom_point() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n Discussion\n\nWhat is the difference between these three plots?\n\n\n\nInteractive graphs with Plotly and ggiraph\nPlotly for ggplot2 is a browser-based charting library that converts ggplots into interactive visualisations:\n\nlibrary(plotly)\np2 &lt;- ggplot(iris2,aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) + geom_point()\ngp2 &lt;- ggplotly(p2)\n\nBy default the mouse over text is what is mapped in the aesthetics. You can add a text aesthetic to add this to the tooltip text.\n\np2 &lt;- p2+ geom_point(aes(text = Country))\ngp2 &lt;- ggplotly(p2)\n\nInteractive plotly graphics open in the Viewer pane in Rstudio and can be embedded in R Markdown documents. Alternatively you can save them as individual web pages using the htmlwidgets package:\n\n#View plotly\ngp2\n\n\n\n\n\n\nYou can save plotly objects as html web pages:\n\nhtmlwidgets::saveWidget(as_widget(gp2), \"plotly_image.html\")\n\nggiraph is another package that allows you to create interactive graphics. It is particularly useful for creating interactive plots for the web.\nInstead of geom_point() we use geom_point_interactive() from the ggiraph package. We then use the girafe() function to render the plot. The tooltip is set in the aesthetics.\n\nlibrary(ggiraph)\ngg &lt;- ggplot(iris2, aes(x = Sepal.Length, y = Sepal.Width,  colour = Species, tooltip = Country)) +\n  geom_point_interactive()\n\ngirafe(ggobj = gg)\n\n\n\n\n\n\n\nCreating detailed graphics with ggpubr\nThe ggpubr package provides wrapper functions for ggplot that make it easier to generate complex, publication ready graphics. It includes functions for running statistical tests and displaying the results in the plot. After using ggpubr, you will need to reset your theme with theme_set().\n\n# Violin plots with box plots inside\ndata(\"ToothGrowth\")\ndf &lt;- ToothGrowth\n\nmy_comparisons &lt;- list( c(\"0.5\", \"1\"), c(\"1\", \"2\"), c(\"0.5\", \"2\") )\n\nggviolin(df, x = \"dose\", y = \"len\", fill = \"dose\",\n         palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n         add = \"boxplot\", add.params = list(fill = \"white\")) +\n  stat_compare_means(comparisons = my_comparisons, label = \"p.signif\") + # Add significance levels\n  stat_compare_means(label.y = 50)                                      # Add p-value \n\n\n\n\n\n\n\n\nThe next example additionally uses the library cowplot to add density plots within the margins of the main figure. Don’t worry if you get lost here, this is just a demonstration of what’s possible in R and beyond the scope of this course.\n\nlibrary(cowplot) \n# Main plot\npmain &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  ggpubr::color_palette(\"jco\")\n# Marginal densities along x axis\nxdens &lt;- axis_canvas(pmain, axis = \"x\") +\n  geom_density(data = iris, aes(x = Sepal.Length, fill = Species),\n              alpha = 0.7, linewidth = 0.2)+\n  ggpubr::fill_palette(\"jco\")\n# Marginal densities along y axis\n# Need to set coord_flip = TRUE, if you plan to use coord_flip()\nydens &lt;- axis_canvas(pmain, axis = \"y\", coord_flip = TRUE)+\n  geom_density(data = iris, aes(x = Sepal.Width, fill = Species),\n                alpha = 0.7, linewidth = 0.2)+\n  coord_flip() +\n  ggpubr::fill_palette(\"jco\")\np1 &lt;- insert_xaxis_grob(pmain, xdens, grid::unit(.2, \"null\"), position = \"top\")\np2 &lt;- insert_yaxis_grob(p1, ydens, grid::unit(.2, \"null\"), position = \"right\")\nggdraw(p2)\n\n\n\n\n\n\n\n\n\n\n Final Challenge:\n\nSpend the remaining time playing around with the different ggplot options and see if you can create an interesting and appealing visualisation with a dataset of your choice.\n\nUse these resources for inspiration!\n\nggplot cheatsheet\nR graph gallery\nggplot extensions\n\n\n\n\n\n Key points\n\n\nggplot2 builds graphics layer upon layer\nBind a dataset to your ggplot function and map values to visual aesthetics\nApply different geometries to create different graphics\nUse colours, fills, gradients, shapes etc. to represent multiple variables\nUse themes to alter the appearance of a graphic\nGenerate sublots with facetting\nSave your graphics with ggsave\nThere are many additional libraries that extend the functionality of ggplot"
  },
  {
    "objectID": "03-Setup.html",
    "href": "03-Setup.html",
    "title": "Setup",
    "section": "",
    "text": "Project Setup\n\nCreate a new project in RStudio called Tidyverse.\nInstall the following packages:\n\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"cowplot\")\n\n## ggplot extensions and themes\ninstall.packages(\"ggthemes\")\ninstall.packages(\"ggrepel\")\ninstall.packages(\"ggsci\")\ninstall.packages(\"ggpubr\")\ninstall.packages(\"patchwork\")\ninstall.packages(\"gghighlight\")\ninstall.packages(\"ggiraph\")\n\n## Colour pallettes\ninstall.packages(\"viridis\")\ninstall.packages(\"RColorBrewer\")\n\n## Interactive plotting\ninstall.packages(\"plotly\")\n\n\n\nData\nYou will need to download data throughout this session using the download.file() function in R.\nIf you are using a Windows computer you will need to explicitly add the argument mode = \"wb\".\n\n## Create a directory to store the data\ndir.create(\"data\")\n\n## Mac or Linux\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data2.xlsx\", destfile = \"data/qpcr_data2.xlsx\")\n\n## Windows\ndownload.file(\"http://bifx-core3.bio.ed.ac.uk/training/DSB/data/qPCR_data2.xlsx\", destfile = \"data/qpcr_data2.xlsx\", mode = \"wb\")"
  },
  {
    "objectID": "03-dplyr.html",
    "href": "03-dplyr.html",
    "title": "Data manipulation and tidying",
    "section": "",
    "text": "Import data into a tidy structure\nFormat, filter and manipulate your datasets in preparation for plotting\nUnderstand the reason and methods for long and wide data formats\nIn this session we will learn how to import data into R and manipulate it using the dplyr package. We will also learn how to reshape data using the tidyr package. These are important steps in the data analysis workflow and will allow you to prepare your data for plotting with ggplot2 in the next session.\nThe dplyr package is specifically designed for data formatting and manipulation and allows you to merge datasets and create new columns as well as filtering and summarising your data. We are going to learn some of the most common functions."
  },
  {
    "objectID": "03-dplyr.html#selecting-columns-and-filtering-rows",
    "href": "03-dplyr.html#selecting-columns-and-filtering-rows",
    "title": "Data manipulation and tidying",
    "section": "Selecting columns and filtering rows",
    "text": "Selecting columns and filtering rows\nFirst, make sure the tidyverse package is loaded and you have read in the surveys dataset.\n\nlibrary(tidyverse)\nsurveys &lt;- read_csv(\"http://bifx-core3.bio.ed.ac.uk/training/R_dplyr_and_ggplot2/data/surveys_complete.csv\")\n\nTo select columns of a tibble, use select(). The first argument to this function is the data frame surveys, and the subsequent arguments are the columns to keep.\n\nselect(surveys, plot_id, species_id, weight)\n\nTo drop columns from a tibble, put a “-” in front of the variable to exclude it.\n\nselect(surveys, -record_id, -species_id)\n\nThis will select all the variables in surveys except record_id and species_id.\nTo choose rows based on specific criteria, use filter():\n\nfilter(surveys, year == 1995)"
  },
  {
    "objectID": "03-dplyr.html#pipes",
    "href": "03-dplyr.html#pipes",
    "title": "Data manipulation and tidying",
    "section": "Pipes",
    "text": "Pipes\nWhat if you want to select and filter at the same time? There are three ways to do this:\n\nIntermediate objects\nNested functions\nPipes\n\nWith intermediate objects, you create a temporary tibble and use that as input to the next function, like this:\n\nsurveys2 &lt;- filter(surveys, weight &lt; 5)\nsurveys_sml &lt;- select(surveys2, species_id, sex, weight)\n\nThis is readable, but can clutter up your workspace with lots of objects that you have to name individually and keep track of.\nYou can also nest functions (i.e. one function inside of another), like this:\n\nsurveys_sml &lt;- select(filter(surveys, weight &lt; 5), species_id, sex, weight)\n\nThis is handy, but can be difficult to read if too many functions are nested. R evaluates the expression from the inside out (in this case, filtering, then selecting).\nThe alternative is to use pipes. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. Pipes in R look like %&gt;% or |&gt;. If you use RStudio, the keyboard shortcut for a pipe is Ctrl + Shift + M.\n\nsurveys |&gt;\n  filter(weight &lt; 5) |&gt;\n  select(species_id, sex, weight)\n\nHere we are ‘piping’ the surveys dataset through the filter() function, then through select(). Since |&gt; takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the tibble as an argument to the filter() and select() functions any more.\nSome may find it helpful to read the pipe like the word “then”. For instance, in the above example, we took the data frame surveys, then we filtered for rows with weight &lt; 5, then we selected columns species_id, sex, and weight. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe, we can accomplish more complex manipulations of data.\nIf we want to create a new object with this smaller version of the data, we can assign it a new name:\n\nsurveys_sml &lt;- surveys |&gt;\n  filter(weight &lt; 5) |&gt;\n  select(species_id, sex, weight)\nsurveys_sml\n\n\n\n Further Learning\n\nPiping was originally introduced by the magrittr package which uses the %&gt;% symbol. Magrittr is part of the tidyverse and loads automatically with dplyr.\nR version 4.1 introduced a native pipe which can be used in base R without loading the magrittr or tidyverse packages. It uses the alternative |&gt; symbol. There are some subtle differences with this pipe which you can read about here. You can change the CTRL+ALT+M keyboard shortcut to use the native pipe in the Code section of RStudio’s Global Options.\n\n\n\n\n Challenge:\n\nUsing pipes, subset the surveys data to include animals collected before 1995 and retain only the columns year, sex, and weight.\n\n\n\n\nSolution. \n\n Solution:\n\n\nsurveys |&gt;\n  filter(year &lt; 1995) |&gt;\n  select(year, sex, weight)\n\n# A tibble: 18,044 × 3\n    year sex   weight\n   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n 1  1978 M        204\n 2  1978 M        199\n 3  1978 M        197\n 4  1979 M        166\n 5  1979 M        184\n 6  1979 M        206\n 7  1979 F        274\n 8  1979 F        186\n 9  1980 F        184\n10  1980 F         87\n# ℹ 18,034 more rows"
  },
  {
    "objectID": "03-dplyr.html#exporting-data",
    "href": "03-dplyr.html#exporting-data",
    "title": "Data manipulation and tidying",
    "section": "Exporting data",
    "text": "Exporting data\nSimilar to the read_csv() function there is also a write_csv() function. If you want to export any of your newly created datasets you can do this as follows:\n\n##Create a data folder\ndir.create(\"data\")\n\nwrite_csv(surveys_sml, file = \"data/surveys_small.csv\")\n#Or use write_tsv for tab separated files\n\nYou can even pipe directly into write_csv to avoid creating another R object.\n\nsurveys |&gt;\n  filter(weight &lt; 5) |&gt;\n  select(species_id, sex, weight) |&gt; \n  write_csv(file = \"data/surveys_small.csv\")"
  },
  {
    "objectID": "03-dplyr.html#mutate",
    "href": "03-dplyr.html#mutate",
    "title": "Data manipulation and tidying",
    "section": "Mutate",
    "text": "Mutate\nFrequently, you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to combine values from two columns. For this we use mutate().\nTo create a new column of weight in kg:\n\nsurveys |&gt;\n  mutate(weight_kg = weight / 1000)\n\nYou can also create a second new column based on the first new column within the same call of mutate():\n\nsurveys |&gt;\n  mutate(weight_kg = weight / 1000,\n         weight_lb = weight_kg * 2.2)\n\nIf you just want to see the first few rows, you can use a pipe to one of the head commands. Base R has head() function and the Tidyverse uses slice_head() which is one of the useful slice functions for selecting specific rows of a dataframe or tibble.\n\nsurveys |&gt;\n  mutate(weight_kg = weight / 1000) |&gt;\n  head()\n\nsurveys |&gt;\n  mutate(weight_kg = weight / 1000) |&gt;\n  slice_head(n=6)\n\nYou can even use functions within mutate. Look at the code below and see if you can figure out how the case_when function works.\n\nsurveys |&gt;\n  mutate(sex = case_when(sex==\"M\"~\"Male\",sex==\"F\"~\"Female\"))\n\nThe stringr package within the Tidyverse contains a lot of useful functions for manipulating character strings. For instance, let’s imagine that the genus ‘Perognathus’ has been mislabeled in our table and should instead be ‘Peromyscus’.\n\nsurveys |&gt;\n  mutate(genus = str_replace(genus,\"Perognathus\",\"Peromyscus\"))\n\nWe can check this has worked by pulling the genus column, converting it to a factor and running a summary.\n\n# summarise the genus column in surveys\nsurveys |&gt;\n  pull(genus) |&gt; # pull extracts a single column\n  as.factor() |&gt; # convert character to factor (categorical variable)\n  summary()\n\n# Try again, replacing Perognathus with Peromyscus\nsurveys |&gt;\n  mutate(genus = str_replace(genus,\"Perognathus\",\"Peromyscus\")) |&gt; \n  pull(genus) |&gt; # pull extracts a single column\n  as.factor() |&gt; # convert character to factor (categorical variable)\n  summary()\n\n\n\n Challenge:\n\nCreate a new data frame from the surveys data that meets the following criteria: Contains only the species_id column and a new column called hindfoot_cm containing the hindfoot_length values converted to centimeters. In this hindfoot_cm column all values are less than 3.\nHint: think about how the commands should be ordered to produce this data frame!\n\n\n\n\nSolution. \n\n Solution:\n\n\nsurveys_hindfoot_cm &lt;- surveys |&gt;\n    mutate(hindfoot_cm = hindfoot_length / 10) |&gt;\n    filter(hindfoot_cm &lt; 3) |&gt;\n    select(species_id, hindfoot_cm)"
  },
  {
    "objectID": "03-dplyr.html#group_by-and-summarise",
    "href": "03-dplyr.html#group_by-and-summarise",
    "title": "Data manipulation and tidying",
    "section": "Group_by and summarise",
    "text": "Group_by and summarise\nMany data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function.\ngroup_by() is often used together with summarise(), which collapses each group into a single-row summary of that group. The group_by() function takes the column names that contain the grouping variables for which you want to calculate summary statistics. The summarise() function computes a summary statistic for each group using a specified function and variable. So to compute the mean weight by sex:\n\nsurveys |&gt;\n  group_by(sex) |&gt;\n  summarise(mean_weight = mean(weight))\n\nYou can also group by multiple columns:\n\nsurveys |&gt;\n  group_by(sex, species_id) |&gt;\n  summarise(mean_weight = mean(weight))\n\nOnce the data are grouped, you can create multiple summary columns at the same time. For instance, we could add columns indicating the minimum weight and mean hindfoot length for each species for each sex:\n\nsurveys |&gt;\n  group_by(sex, species_id) |&gt;\n  summarise(min_weight = min(weight),\n            mean_hindfoot_length = mean(hindfoot_length))\n\nIt is sometimes useful to rearrange the result of a query to inspect the values. For instance, we can sort on min_weight to put the lighter species first and :\n\nsurveys |&gt;\n  group_by(sex, species_id) |&gt;\n  summarise(min_weight = min(weight),\n            mean_hindfoot_length = mean(hindfoot_length)) |&gt;\n  arrange(min_weight)\n\nTo sort in descending order, we need to add the desc() function. If we want to sort the results by decreasing order of mean weight:\n\nsurveys |&gt;\n  group_by(sex, species_id) |&gt;\n  summarise(min_weight = min(weight),\n            mean_hindfoot_length = mean(hindfoot_length)) |&gt;\n  arrange(desc(min_weight))"
  },
  {
    "objectID": "03-dplyr.html#count",
    "href": "03-dplyr.html#count",
    "title": "Data manipulation and tidying",
    "section": "Count",
    "text": "Count\nWhen working with data, we often want to know the number of observations found for each factor or combination of factors. For this task, dplyr provides count(). For example, if we wanted to count the number of rows of data for each sex, we would do:\n\nsurveys |&gt;\n    count(sex) \n\nThe count() function is shorthand for something we’ve already seen: grouping by a variable, and summarising it by counting the number of observations in that group. In other words, surveys |&gt; count(sex) is equivalent to:\n\nsurveys |&gt;\n    group_by(sex) |&gt;\n    summarise(count = n()) #n() counts the size of each group\n\nIf we wanted to count a combination of factors, such as sex and species, we would specify the first and the second factor as the arguments of count():\n\nsurveys |&gt;\n  count(sex, species) \n\nWith the above code, we can proceed with arrange() to sort the table according to a number of criteria so that we have a better comparison. For instance, we might want to arrange the table above in (i) an alphabetical order of the levels of the species and (ii) in descending order of the count:\n\nsurveys |&gt;\n  count(sex, species) |&gt;\n  arrange(species, desc(n))\n\n\n\n Challenge:\n\nHow many animals were caught in each plot_type surveyed?\n\n\n\n\nSolution. \n\n Solution:\n\n\nsurveys |&gt;\n    count(plot_type) \n\n\n\nUse group_by() and summarise() to find the mean, min, and max hindfoot length for each species (using species_id). Also add the number of observations (hint: see ?n).\n\n\n\n\nSolution. \n\n Solution:\n\n\nsurveys |&gt;\n   group_by(species_id) |&gt;\n   summarise(\n       mean_hindfoot_length = mean(hindfoot_length),\n       min_hindfoot_length = min(hindfoot_length),\n       max_hindfoot_length = max(hindfoot_length),\n       n = n())\n\n\n\nWhat was the heaviest animal measured in each year? Return the columns year, genus, species_id, and weight. Order the output by year.\n\n\n\n\nSolution. \n\n Solution:\n\n\nsurveys |&gt;\n   group_by(year) |&gt;\n   filter(weight == max(weight)) |&gt;\n   select(year, genus, species, weight) |&gt;\n   arrange(year)\n\n\n\n\n\n\n\n Discussion\n\n\nLook at the surveys dataset with the print() function. How many rows and columns does it have?\nBy default, tibbles hide a lot of the data to prevent the screen from getting crowded. How can you show more rows and all of the columns?\nWhat other questions can we ask of this dataset? Set a challenge for a partner or your group using the dplyr functions.\n\n\n\n\n\n Further Learning\n\nExamples of more dplyr functions are available on the dplyr website."
  },
  {
    "objectID": "03-dplyr.html#pivoting-functions-in-tidyr",
    "href": "03-dplyr.html#pivoting-functions-in-tidyr",
    "title": "dplyr",
    "section": "Pivoting functions in tidyr",
    "text": "Pivoting functions in tidyr\nThe tidyr package contains the functions pivot_longer() and pivot_wider() which allow you to transform a dataset between long and wide formats. For instance, what if we wanted to compare the mean weights of each species at each plot (using plot_id).\nWe’d need to create a new table where each row is comprised of values of variables associated with each plot. In practical terms this means the values in genus would become the names of column variables and the cells would contain the values of the mean weight observed on each plot.\n\nHaving created a new table, it is then straightforward to explore the relationship between the weight of different genera within, and between, the plots. The key point here is that we are still following a tidy data structure,but we have reshaped the data according to the observation of interest. Mean genus weight per plot, instead of recordings per date.\nFirst, lets create surveys_gw where observations for each plot (genus and mean_weight) are spread across multiple rows:\n\nsurveys_gw &lt;- surveys |&gt;\n  group_by(plot_id, genus) |&gt;\n  summarise(mean_weight = mean(weight))\n\nUsing pivot_wider() with genus as the names of the new columns and mean_weight as the values, we can create a table that allows us to compare mean weights of different genera at each plot.\n\nsurveys_wide &lt;- surveys_gw |&gt;\n  pivot_wider(names_from = genus,values_from = mean_weight)\n\nThe opposing situation could occur if we had been provided with data in the form of surveys_wide, where the genus names are column names, but we wish to treat them as values of a variable instead. To do this we can use the pivot_longer() function.\n\n\n Further Learning\n\nExamples of more dplyr functions are available on the dplyr website.\n\n\n\n\n Key points\n\n\nImport and format data with readr and tidyr.\nUse dplyr select, filter and mutate to manipulate datasets\nUse group_by, summarise and count to create summary datasets by groups.\nUse pivot_longer and pivot_wider to move between wide and long formats."
  },
  {
    "objectID": "03-dplyr.html#tidyr",
    "href": "03-dplyr.html#tidyr",
    "title": "Data manipulation and tidying",
    "section": "Tidyr",
    "text": "Tidyr\nThe surveys dataset is complete and already in a tidy format. However, real world datasets are often messy and require some tidying before they can be analysed.\nLet’s simulate an untidy gene expression table to see how we can tidy it up:\n\nexpr_untidy &lt;- tibble(\n  sample_info = c(\"WT_1_liver\", \"WT_2_liver\", \"KO_1_liver\", \"KO_2_liver\"),\n  batch = c(\"A\", \"B\", NA, \"B\"),\n  GeneA = c(120, 135, 98, NA),\n  GeneB = c(300, NA, 250, 275),\n  GeneC = c(50, 60, NA, 80)\n)\n\nexpr_untidy\n\n# A tibble: 4 × 5\n  sample_info batch GeneA GeneB GeneC\n  &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT_1_liver  A       120   300    50\n2 WT_2_liver  B       135    NA    60\n3 KO_1_liver  &lt;NA&gt;     98   250    NA\n4 KO_2_liver  B        NA   275    80\n\n\nThis datasets is untidy because:\n\nThe sample_info column contains multiple pieces of information (genotype, replicate number and tissue type).\nThere are missing values in the dataset.\n\nThe dataset is in a wide format. In this format, each gene is a separate variable. This isn’t ideal if we want to analyse or plot expression for all genes. We will need to convert this to long format.\n\nSeparating columns\nThe tidyr package contains a set of separate functions that split a column into multiple values. In our example, we want to separate the sample_info column into three new columns called genotype, replicate, and tissue.\nBecause this information is separated by the underscore character, we can use the separate_wider_delim() function. This will split the column into three new columns based on the delimiter “_“. The names argument specifies the names of the new columns.\n\nexpr_untidy2 &lt;- expr_untidy |&gt;\n  separate_wider_delim(sample_info, delim = \"_\", names = c(\"genotype\", \"replicate\", \"tissue\"))\n\nexpr_untidy2\n\n# A tibble: 4 × 7\n  genotype replicate tissue batch GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A       120   300    50\n2 WT       2         liver  B       135    NA    60\n3 KO       1         liver  &lt;NA&gt;     98   250    NA\n4 KO       2         liver  B        NA   275    80\n\n\n\n\n Further Learning\n\nOther separate functions can be used for different types of separation e.g\n\nseparate_wider_regex() for separating based on regular expressions.\nseparate_longer_delim() for separating into multiple rows instead of columns.\n\nThere is also a unite() function that does the opposite of separate(). It combines multiple columns into a single column based on a specified delimiter.\n\n\n\nMissing values\nThe tidyr package also contains functions for handling missing values. Missing values are represented in R as NA. There are several ways to handle missing values, depending on the context of your analysis.\nWe might want to check our data for missing values first. The is.na() function can be used to identify which values are missing. For instance, to check for missing values in the entire dataset:\n\nis.na(expr_untidy2) |&gt; any()\n\n[1] TRUE\n\n\nWe can count the number of missing values per column:\n\nis.na(expr_untidy2) |&gt; colSums()\n\n genotype replicate    tissue     batch     GeneA     GeneB     GeneC \n        0         0         0         1         1         1         1 \n\n\nThere are normally three options for handling missing values:\n\nDrop rows with missing values\nReplace missing values with a specific value\nImpute missing values based on other values in the dataset (we won’t cover this today but there are functions and packages that can do this).\n\nThe drop_na() function can be used to drop rows with missing values. For instance, if we wanted to drop all rows with missing values in the GeneB column:\n\nexpr_untidy2 |&gt;\n  drop_na(GeneB)\n\n# A tibble: 3 × 7\n  genotype replicate tissue batch GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A       120   300    50\n2 KO       1         liver  &lt;NA&gt;     98   250    NA\n3 KO       2         liver  B        NA   275    80\n\n\nWe could also drop all rows with missing values in any of the gene columns:\n\nexpr_untidy2 |&gt;\n  drop_na(GeneA, GeneB, GeneC)\n\n# A tibble: 1 × 7\n  genotype replicate tissue batch GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A       120   300    50\n\n\nAs you can see, dropping data is not always the best option, especially if you have a lot of missing values. In this case, you might want to replace the missing values with a specific value, such as 0 or the mean of the column.\n\n## Replace missing values in Gene columns with 0\nexpr_untidy2 |&gt;\n  replace_na(list(GeneA = 0, GeneB = 0, GeneC = 0))\n\n# A tibble: 4 × 7\n  genotype replicate tissue batch GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A       120   300    50\n2 WT       2         liver  B       135     0    60\n3 KO       1         liver  &lt;NA&gt;     98   250     0\n4 KO       2         liver  B         0   275    80\n\n\nThere is also a missing value in the batch column. This could be down to human error during data entry, or it could be that the batch information was not recorded for that sample. If we wanted to fill in the batch with “unknown”, we could add this to the replace_na() function:\n\nexpr_untidy2 |&gt;\n  replace_na(list(batch = \"unknown\", GeneA = 0, GeneB = 0, GeneC = 0))\n\n# A tibble: 4 × 7\n  genotype replicate tissue batch   GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A         120   300    50\n2 WT       2         liver  B         135     0    60\n3 KO       1         liver  unknown    98   250     0\n4 KO       2         liver  B           0   275    80\n\n\nPerhaps we know that batch A was used for the first replicates of the experiment and batch B was used for the second replicate. In this case, we could use a case_when statement within mutate() to fill in the missing batch information based on the replicate number:\n\nexpr_untidy2 |&gt;\n  mutate(batch = case_when(\n    replicate == \"1\" ~ \"A\",\n    replicate == \"2\" ~ \"B\",\n    .default = batch # keep existing value if replicate is not 1 or 2\n  )) |&gt;\n  replace_na(list(GeneA = 0, GeneB = 0, GeneC = 0))\n\n# A tibble: 4 × 7\n  genotype replicate tissue batch GeneA GeneB GeneC\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 WT       1         liver  A       120   300    50\n2 WT       2         liver  B       135     0    60\n3 KO       1         liver  A        98   250     0\n4 KO       2         liver  B         0   275    80\n\n\nThis looks good. Let’s save this as our tidy dataset:\n\nexpr_tidy &lt;- expr_untidy2 |&gt;\n  mutate(batch = case_when(\n    replicate == \"1\" ~ \"A\",\n    replicate == \"2\" ~ \"B\",\n    .default = batch # keep existing value if replicate is not 1 or 2\n  )) |&gt;\n  replace_na(list(GeneA = 0, GeneB = 0, GeneC = 0))\n\n\n\n Further Learning\n\nThe fill() function is another useful function for replacing NA values. It can be used to fill in missing values based on the values in the rows above or below.\n\n\n\nReshaping data\nAlthough our dataset is now tidy, it is still in a wide format. This means that each gene is a separate variable and we have one row per sample. We have already seen that it is quite cumbersome to list all of the separate gene columns when we want to do something to all of the genes at once (e.g. replace NA values with 0). It would be much easier if we had a long format dataset where we have one row per gene per sample, and a column that indicates which gene is which.\nWe often need to reshape our data to make it easier to work with. The tidyr package contains functions for reshaping data, such as pivot_longer() and pivot_wider(). These functions allow you to transform a dataset between long and wide formats.\n\nTo convert our dataset from wide to long format, we can use the pivot_longer() function. This function takes the columns that we want to pivot and creates two new columns: one for the names of the original columns (in this case, the gene names) and one for the values (in this case, the expression values).\n\nexpr_tidy |&gt;\n  pivot_longer(cols = starts_with(\"Gene\"), names_to = \"gene\", values_to\n = \"expression\")\n\n# A tibble: 12 × 6\n   genotype replicate tissue batch gene  expression\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 WT       1         liver  A     GeneA        120\n 2 WT       1         liver  A     GeneB        300\n 3 WT       1         liver  A     GeneC         50\n 4 WT       2         liver  B     GeneA        135\n 5 WT       2         liver  B     GeneB          0\n 6 WT       2         liver  B     GeneC         60\n 7 KO       1         liver  A     GeneA         98\n 8 KO       1         liver  A     GeneB        250\n 9 KO       1         liver  A     GeneC          0\n10 KO       2         liver  B     GeneA          0\n11 KO       2         liver  B     GeneB        275\n12 KO       2         liver  B     GeneC         80\n\n\nFinally, we could use pipes to combine all of the tidying steps into one workflow:\n\nexpr_long &lt;- expr_untidy |&gt;\n  separate_wider_delim(sample_info, delim = \"_\", names = c(\"genotype\", \"replicate\", \"tissue\")) |&gt;\n  mutate(batch = case_when(\n    replicate == \"1\" ~ \"A\",\n    replicate == \"2\" ~ \"B\",\n    .default = batch # keep existing value if replicate is not 1 or 2\n  )) |&gt;\n  replace_na(list(batch = \"unknown\", GeneA = 0, GeneB = 0, GeneC = 0)) |&gt;\n  pivot_longer(cols = starts_with(\"Gene\"), names_to = \"gene\", values_to = \"expression\")\n\nexpr_long\n\n# A tibble: 12 × 6\n   genotype replicate tissue batch gene  expression\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 WT       1         liver  A     GeneA        120\n 2 WT       1         liver  A     GeneB        300\n 3 WT       1         liver  A     GeneC         50\n 4 WT       2         liver  B     GeneA        135\n 5 WT       2         liver  B     GeneB          0\n 6 WT       2         liver  B     GeneC         60\n 7 KO       1         liver  A     GeneA         98\n 8 KO       1         liver  A     GeneB        250\n 9 KO       1         liver  A     GeneC          0\n10 KO       2         liver  B     GeneA          0\n11 KO       2         liver  B     GeneB        275\n12 KO       2         liver  B     GeneC         80\n\n\n\n\n Further Learning\n\nExamples of more dplyr functions are available on the tidyr website.\n\n\n\n\n Key points\n\n\nImport and format data with readr and tidyr.\nUse dplyr select, filter and mutate to manipulate datasets\nUse arrange to sort datasets by specific variables.\nUse group_by, summarise and count to create summary datasets by groups.\nUse tidyr functions to tidy and reshape datasets.\n\nMove between wide and long formats with pivot_longer and pivot_wider."
  },
  {
    "objectID": "03-ggplot2.html#additional-functions-to-enhance-plotting",
    "href": "03-ggplot2.html#additional-functions-to-enhance-plotting",
    "title": "ggplot2",
    "section": "Additional functions to enhance plotting",
    "text": "Additional functions to enhance plotting\n\nCut functions\nThe cut_* functions in ggplot2 can turn continuous data into discrete levels so they can be plotted as categorical labels. In this example we create a new column that bins the data into 5 groups of equal size based on Sepal.Length:\n\niris2 &lt;- iris2 |&gt; mutate(Sepal.Length.Group = cut_number(Sepal.Length, 5))\n\niris2 |&gt; head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Ratio Country\n1          5.1         3.5          1.4         0.2  setosa    1.457143  France\n2          4.9         3.0          1.4         0.2  setosa    1.633333   Italy\n3          4.7         3.2          1.3         0.2  setosa    1.468750   Italy\n4          4.6         3.1          1.5         0.2  setosa    1.483871  France\n5          5.0         3.6          1.4         0.2  setosa    1.388889   Italy\n6          5.4         3.9          1.7         0.4  setosa    1.384615   Spain\n  Sepal.Length.Group\n1            (5,5.6]\n2            [4.3,5]\n3            [4.3,5]\n4            [4.3,5]\n5            [4.3,5]\n6            (5,5.6]\n\n\n\n\n Discussion\n\nTake a look at the new column Sepal.Length.Group. How are the groups defined? What are the cut points for each group?\nHave a look at the difference between the cut_number, cut_interval and cut_width functions.\n\n\nLet’s use the new column to colour our data:\n\nggplot(iris2, aes(Sepal.Length, Sepal.Width, fill = Sepal.Length.Group)) +\n  geom_violin() +\n  labs(fill = \"Sepal length intervals\", x = \"Sepal length\", y = \"Sepal width\")\n\n\n\n\n\n\n\n\nNote the use of the labs() function to change multiple labels at once.\n\n\nScaling data\nLet’s look at a larger dataset like the surveys_complete data we used earlier:\n\nggplot(surveys,aes(weight, hindfoot_length)) +\n  geom_point()\n\n\n\n\n\n\n\n\nFor axes with large values or very dispersed values it can be useful to rescale using a log axis. This can be done in two ways:\n\n## We can transform the x values in our ggplot call:\nggplot(surveys, aes(log10(weight), hindfoot_length)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n## OR we can change the x-axis to a log scale\nggplot(surveys,aes(weight, hindfoot_length)) +\n  geom_point() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n Discussion\n\nWhat is the difference between these three plots?\n\n\n\nInteractive plots with Plotly\nPlotly is an alternative charting library to ggplot2 and has its own set of plotting functions. Because it is designed for the web, it can output dynamic and interactive content. Plotly includes a function to convert ggplots into plotly style widgets.\n\nlibrary(plotly)\n\np2 &lt;- ggplot(iris2, aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) + \n  geom_point()\n\nggplotly(p2)\n\n\n\n\n\n\nWith plotly widgets you can: - Hover over points to see more information - Zoom and pan around the plot - Select groups of points by clicking and double-clicking the legend\nBy default, the hover text is whatever is mapped in the aesthetics. You can add a text aesthetic to add this to the tooltip text.\n\np2 &lt;- ggplot(iris2, aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) + \n  geom_point(aes(text = Country))\n\n## Show all aesthetics in tooltip\nggplotly(p2)\n\n\n\n\n## Show only the text aesthetic in tooltip\nggplotly(p2, tooltip = \"text\")\n\n\n\n\n\nInteractive plotly graphics are built using html, the language of the web. They open in the Viewer pane in Rstudio which is used for web content.\nThis means they cannot be saved in static file formats like PDF or PNG. Alternatively you can save them as individual web pages using the htmlwidgets package:\n\nhtmlwidgets::saveWidget(as_widget(gp2), \"plotly_image.html\")\n\nAlternatively, you can embedded them in R Markdown or quarto documents, which we will visit later on.\n\n\nInteractive graphics with ggiraph\nggiraph is another package that allows you to create interactive graphics. It is particularly useful for creating interactive plots for the web.\nInstead of geom_point() we use geom_point_interactive() from the ggiraph package. We then use the girafe() function to render the plot. The tooltip is set in the aesthetics.\n\nlibrary(ggiraph)\n\ngg &lt;- ggplot(iris2, aes(x = Sepal.Length, y = Sepal.Width,  colour = Species, tooltip = Country)) +\n  geom_point_interactive()\n\ngirafe(ggobj = gg)\n\n\n\n\n\n\n\nCreating detailed graphics with ggpubr\nThe ggpubr package provides wrapper functions for ggplot that make it easier to generate complex, publication ready graphics. It includes functions for running statistical tests and displaying the results in the plot. After using ggpubr, you will need to reset your theme with theme_set().\nDon’t worry about the details of the code below, this is just to show you some of the possibilities with ggpubr.\n\n# Violin plots with box plots inside\ndata(\"ToothGrowth\")\ndf &lt;- ToothGrowth\n\nmy_comparisons &lt;- list( c(\"0.5\", \"1\"), c(\"1\", \"2\"), c(\"0.5\", \"2\") )\n\nggviolin(df, x = \"dose\", y = \"len\", fill = \"dose\",\n         palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n         add = \"boxplot\", add.params = list(fill = \"white\")) +\n  stat_compare_means(comparisons = my_comparisons, label = \"p.signif\") + # Add significance levels\n  stat_compare_means(label.y = 50)                                      # Add p-value \n\n\n\n\n\n\n\n\nThe next example additionally uses the library cowplot to add density plots within the margins of the main figure. Don’t worry if you get lost here, this is just a demonstration of what’s possible in R and beyond the scope of this course.\n\nlibrary(cowplot) \n# Main plot\npmain &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  ggpubr::color_palette(\"jco\")\n# Marginal densities along x axis\nxdens &lt;- axis_canvas(pmain, axis = \"x\") +\n  geom_density(data = iris, aes(x = Sepal.Length, fill = Species),\n              alpha = 0.7, linewidth = 0.2)+\n  ggpubr::fill_palette(\"jco\")\n# Marginal densities along y axis\n# Need to set coord_flip = TRUE, if you plan to use coord_flip()\nydens &lt;- axis_canvas(pmain, axis = \"y\", coord_flip = TRUE)+\n  geom_density(data = iris, aes(x = Sepal.Width, fill = Species),\n                alpha = 0.7, linewidth = 0.2)+\n  coord_flip() +\n  ggpubr::fill_palette(\"jco\")\np1 &lt;- insert_xaxis_grob(pmain, xdens, grid::unit(.2, \"null\"), position = \"top\")\np2 &lt;- insert_yaxis_grob(p1, ydens, grid::unit(.2, \"null\"), position = \"right\")\nggdraw(p2)\n\n\n\n\n\n\n\n\n\n\n Challenge:\n\nSpend the remaining time playing around with the different ggplot options and see if you can create an interesting and appealing visualisation with a dataset of your choice.\n\nUse these resources for inspiration!\n\nggplot cheatsheet\nR graph gallery\nggplot extensions\n\n\n\n\n\n Further Learning\n\n\nggplot2 website\nR for Data Science (free online book)\n\n\n\n\n\n Key points\n\n\nggplot2 builds graphics layer upon layer\nBind a data set to your ggplot function and map values to visual aesthetics\nApply different geometries to create different graphics\nUse colours, fills, gradients, shapes etc. to represent multiple variables\nUse **themes* to alter the appearance of a graphic\nGenerate sublots with faceting\nSave your graphics with ggsave\nThere are many additional libraries that extend the functionality of ggplot"
  }
]